{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ba7fc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "from tensorflow.keras.layers import RepeatVector, Concatenate, Dense, Dot, Activation\n",
    "from tensorflow.keras.layers import Input, Bidirectional, LSTM\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from babel.dates import format_date\n",
    "import os \n",
    "\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"]=\"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "145c94be",
   "metadata": {},
   "outputs": [],
   "source": [
    "faker = Faker()\n",
    "np.random.seed(5)\n",
    "BATCH_SIZE=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25fcc685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "short => 4/4/79\n",
      "medium => Oct 31, 1984\n",
      "medium => Dec 22, 1979\n",
      "medium => Jan 10, 2015\n",
      "long => October 4, 2019\n",
      "long => August 11, 2005\n",
      "long => April 26, 1973\n",
      "long => January 26, 1999\n",
      "long => September 25, 2004\n",
      "full => Friday, June 9, 2000\n",
      "full => Saturday, March 12, 2005\n",
      "full => Sunday, July 24, 1977\n",
      "d MMM YYY => 11 Sep 2001\n",
      "d MMMM YYY => 3 March 1971\n",
      "d MMMM YYY => 17 July 1988\n",
      "d MMMM YYY => 18 April 2003\n",
      "d MMMM YYY => 24 January 1979\n",
      "d MMMM YYY => 13 November 2001\n",
      "dd/MM/YYY => 01/01/1981\n",
      "EE d, MMM YYY => Tue 6, Feb 1973\n",
      "EEEE d, MMMM YYY => Friday 1, December 1972\n",
      "MMM d, YYY => Feb 15, 1992\n",
      "MMMM d, YYY => December 16, 2020\n",
      "YYY, d MMM => 2017, 26 Oct\n",
      "YYY, d MMMM => 1977, 8 September\n",
      "EE YYY, d MMMM => Tue 2009, 6 October\n",
      "EEEE YYY, d MM => Sunday 2004, 21 03\n"
     ]
    }
   ],
   "source": [
    "FORMATS = ['short',\n",
    "           'medium',\n",
    "           'medium',\n",
    "           'medium',\n",
    "           'long','long',\n",
    "           'long','long',\n",
    "           'long','full',\n",
    "           'full','full',\n",
    "           'd MMM YYY',\n",
    "           'd MMMM YYY',\n",
    "           'd MMMM YYY',\n",
    "           'd MMMM YYY',\n",
    "           'd MMMM YYY',\n",
    "           'd MMMM YYY',\n",
    "           'dd/MM/YYY',\n",
    "           'EE d, MMM YYY',\n",
    "           'EEEE d, MMMM YYY',\n",
    "           'MMM d, YYY',\n",
    "           'MMMM d, YYY',\n",
    "           'YYY, d MMM',\n",
    "           'YYY, d MMMM',\n",
    "           'EE YYY, d MMMM',\n",
    "           'EEEE YYY, d MM'\n",
    "          ]\n",
    "for format in FORMATS:\n",
    "    print('%s => %s' %(format, format_date(faker.date_object(), format=format, locale='en')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2cf5805",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_date():\n",
    "    dt = faker.date_time_between(start_date = '-500y',end_date='+50y')\n",
    "    try:\n",
    "        date = format_date(dt, format=random.choice(FORMATS), locale='en')\n",
    "        human_readable = date.lower().replace(',', '')\n",
    "        machine_readable =  format_date(dt, format=\"YYYY-MM-dd\", locale='en')\n",
    "    except AttributeError as e:\n",
    "        return None, None, None\n",
    "    return human_readable, machine_readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e702519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('thursday 1877 19 04', '1877-04-19')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b1073f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51200 36 12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('friday 7 november 1862', '1862-11-07'),\n",
       " ('fri 8 oct 1909', '1909-10-08'),\n",
       " ('december 10 1618', '1618-12-10'),\n",
       " ('friday july 25 1947', '1947-07-25'),\n",
       " ('november 19 1797', '1797-11-19'),\n",
       " ('mar 2 1884', '1884-03-02'),\n",
       " ('1786 7 sep', '1786-09-07'),\n",
       " ('25/09/1912', '1912-09-25'),\n",
       " ('dec 23 2064', '2064-12-23'),\n",
       " ('1594 4 march', '1594-03-04')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_vocab = set()\n",
    "machine_vocab = set()\n",
    "dataset = []\n",
    "m = int(BATCH_SIZE*100*4)\n",
    "\n",
    "for i in range(m):\n",
    "  hd,md = random_date()\n",
    "  dataset.append((hd,md))\n",
    "  human_vocab.update( tuple(hd) )\n",
    "  machine_vocab.update( tuple(md) )\n",
    "    \n",
    "# self-made tokenization\n",
    "  \n",
    "human_vocab.update(('<pad>','<unk>'))\n",
    "human_vocab = dict(enumerate(human_vocab))\n",
    "# human_vocab = tokenizer.word_index\n",
    "human_vocab = { v:i for i,v in human_vocab.items()  }\n",
    "human_vocab_index_word = dict(enumerate(human_vocab))\n",
    "\n",
    "machine_vocab.add('<unk>')\n",
    "machine_vocab = dict(enumerate(machine_vocab))\n",
    "# word_index\n",
    "inv_machine_vocab = { v:i for i,v in machine_vocab.items()}\n",
    "\n",
    "print(len(dataset),len(human_vocab),len(machine_vocab))\n",
    "dataset[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "327881f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test set\n",
    "t = BATCH_SIZE*10*4\n",
    "testset= []\n",
    "for i in range(t):\n",
    "  hd,md = random_date()\n",
    "  testset.append((hd,md))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a005960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 12\n"
     ]
    }
   ],
   "source": [
    "HUMAN_VOCAB = len(human_vocab)\n",
    "MACHINE_VOCAB = len(machine_vocab)\n",
    "batch_size=128\n",
    "Tx = 30\n",
    "Ty = 10\n",
    "print( HUMAN_VOCAB, MACHINE_VOCAB )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "645cf445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_ohe(string, T, vocab):\n",
    "    # in a seq-to-seq model batch of one-hot vectors is the expected output of the final softmax layer\n",
    "    # vocab play the role as tokenizer.word_index, i.e., word to index\n",
    "    # in the past I work on tokenizing words, this time we tokenizer every single characters\n",
    "    string = string.lower()\n",
    "    arr = []\n",
    "    while len(arr) < len(string):\n",
    "        curr_index = len(arr)\n",
    "        arr.append(vocab.get(string[curr_index], vocab['<unk>']))\n",
    "\n",
    "    while len(arr) < T:\n",
    "        arr.append(vocab['<pad>'])\n",
    "    \n",
    "    onehot = np.zeros((T,len(vocab)))\n",
    "    for i in range(T):\n",
    "        onehot[i, arr[i]] = 1\n",
    "        \n",
    "    return onehot, arr\n",
    "\n",
    "def output_to_date(out, vocab):\n",
    "    # this time the \"vocab\" is index_word\n",
    "    arr = np.argmax(out,axis=-1)\n",
    "    string = ''\n",
    "    for i in arr:\n",
    "        string += vocab[i]\n",
    "        \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f29b9462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((51200, 30, 36), (51200, 10, 12))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n",
    "for x,y in dataset:\n",
    "    X.append(string_to_ohe(x, Tx, human_vocab)[0])\n",
    "    Y.append(string_to_ohe(y, Ty, inv_machine_vocab)[0])\n",
    "    \n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "938b7337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7 mar 1875<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_to_date(X[random.randint(0,50000)], human_vocab_index_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0b4e2f3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5120, 30, 36), (5120, 10, 12))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xt = []\n",
    "Yt = []\n",
    "\n",
    "for x,y in testset:\n",
    "    Xt.append(string_to_ohe(x, Tx, human_vocab)[0])\n",
    "    Yt.append(string_to_ohe(y, Ty, inv_machine_vocab)[0])\n",
    "    \n",
    "Xt,Yt = np.array(Xt), np.array(Yt)\n",
    "Xt.shape, Yt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd933378",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combines activations generated from BiLSTM with previous state of Post LSTM cell to get attention to be given to each timestep\n",
    "#heart of attention model\n",
    "\n",
    "def one_step_attention(a, s_prev):\n",
    "    x = RepeatVector(Tx)(s_prev)             \n",
    "    # this is to make use of all the information from output hidden state from the first LSTM layer\n",
    "    # and \"current\" hidden state of second LSTM layer\\\n",
    "    # shape of a: (none, T_x, 2*H_encoder), shape off current x: (none, T_x, H_decoder)\n",
    "    x = Concatenate(axis=-1)([a, x])        \n",
    "    # shape of x: (none, T_x, 2*H_encoder + H_decoder)\n",
    "    e = Dense(Ty, activation='tanh')(x)    \n",
    "    energy = Dense(1, activation='relu')(e) \n",
    "    # shape of energy: (none, T_x, 1)\n",
    "    alphas = Activation('softmax')(energy)\n",
    "    # shape of alphas: (none, T_x)\n",
    "    # alphas are the attention weight\n",
    "    # therefore context is the weighted sum of our first LSTM layer's hidden state\n",
    "    # context can be thought of as fine-tuned output hidden state that is to be fed into decoder LSTM model\n",
    "    context = Dot(axes=1)([alphas,a])\n",
    "    \n",
    "    return context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758c8581",
   "metadata": {},
   "source": [
    "<img width=\"50%\" src=\"./attention_mechanism_2.png\"><img width=\"90%\" src=\"./attention_mechanism_1.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f9350d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_a = 32 #pre attention LSTM state, since Bi directional attention=64\n",
    "n_s = 64 #post attention LSTM state\n",
    "\n",
    "inp = Input((Tx, HUMAN_VOCAB))\n",
    "s0 = Input((n_s,))\n",
    "c0 = Input((n_s,))\n",
    "\n",
    "outputs = []\n",
    "\n",
    "s = s0\n",
    "c = c0\n",
    "a = Bidirectional(\n",
    "    LSTM(\n",
    "        n_a, \n",
    "        batch_input_shape=(batch_size, Tx, HUMAN_VOCAB),\n",
    "        return_sequences=True\n",
    "    ))(inp) #generate hidden state for every timestep\n",
    "\n",
    "postLSTM = LSTM(n_s, return_state = True)\n",
    "\n",
    "output = Dense(MACHINE_VOCAB, activation='softmax') #our final output layer\n",
    "\n",
    "for _ in range(Ty): #iterate for every output step\n",
    "    context = one_step_attention(a, s) #get context\n",
    "    s, _, c = postLSTM(context, initial_state=[s, c]) #generate cell_state_seq(currently 1), cell_state, memory  \n",
    "    out = output(s)\n",
    "    outputs.append(out)\n",
    "  \n",
    "model = Model([inp, s0, c0], outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5d88a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "400/400 [==============================] - 37s 51ms/step - loss: 15.7731 - dense_loss: 0.6692 - dense_1_loss: 1.6972 - dense_2_loss: 1.9641 - dense_3_loss: 2.0815 - dense_4_loss: 0.9155 - dense_5_loss: 1.2792 - dense_6_loss: 2.1925 - dense_7_loss: 1.0459 - dense_8_loss: 1.6271 - dense_9_loss: 2.3009 - dense_acc: 0.8630 - dense_1_acc: 0.3712 - dense_2_acc: 0.2845 - dense_3_acc: 0.2458 - dense_4_acc: 0.8092 - dense_5_acc: 0.4226 - dense_6_acc: 0.2048 - dense_7_acc: 0.7065 - dense_8_acc: 0.3104 - dense_9_acc: 0.1720 - val_loss: 6.8830 - val_dense_loss: 0.1514 - val_dense_1_loss: 0.9220 - val_dense_2_loss: 1.3535 - val_dense_3_loss: 1.3714 - val_dense_4_loss: 0.0163 - val_dense_5_loss: 0.1255 - val_dense_6_loss: 0.7013 - val_dense_7_loss: 0.0206 - val_dense_8_loss: 0.6963 - val_dense_9_loss: 1.5247 - val_dense_acc: 0.9508 - val_dense_1_acc: 0.6049 - val_dense_2_acc: 0.4369 - val_dense_3_acc: 0.4316 - val_dense_4_acc: 1.0000 - val_dense_5_acc: 0.9771 - val_dense_6_acc: 0.8334 - val_dense_7_acc: 0.9998 - val_dense_8_acc: 0.7344 - val_dense_9_acc: 0.3906\n",
      "Epoch 2/100\n",
      "400/400 [==============================] - 16s 41ms/step - loss: 6.3805 - dense_loss: 0.1443 - dense_1_loss: 0.8647 - dense_2_loss: 1.2902 - dense_3_loss: 1.3188 - dense_4_loss: 0.0130 - dense_5_loss: 0.1113 - dense_6_loss: 0.5905 - dense_7_loss: 0.0194 - dense_8_loss: 0.6237 - dense_9_loss: 1.4047 - dense_acc: 0.9537 - dense_1_acc: 0.6323 - dense_2_acc: 0.4513 - dense_3_acc: 0.4534 - dense_4_acc: 1.0000 - dense_5_acc: 0.9763 - dense_6_acc: 0.8699 - dense_7_acc: 0.9997 - dense_8_acc: 0.7666 - dense_9_acc: 0.4511 - val_loss: 5.2715 - val_dense_loss: 0.1112 - val_dense_1_loss: 0.7957 - val_dense_2_loss: 1.2171 - val_dense_3_loss: 1.1369 - val_dense_4_loss: 0.0075 - val_dense_5_loss: 0.0751 - val_dense_6_loss: 0.4132 - val_dense_7_loss: 0.0110 - val_dense_8_loss: 0.4650 - val_dense_9_loss: 1.0389 - val_dense_acc: 0.9633 - val_dense_1_acc: 0.6555 - val_dense_2_acc: 0.4568 - val_dense_3_acc: 0.5219 - val_dense_4_acc: 1.0000 - val_dense_5_acc: 0.9803 - val_dense_6_acc: 0.9043 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.8436 - val_dense_9_acc: 0.6268\n",
      "Epoch 3/100\n",
      "400/400 [==============================] - 16s 41ms/step - loss: 4.9949 - dense_loss: 0.1097 - dense_1_loss: 0.7656 - dense_2_loss: 1.1832 - dense_3_loss: 1.0860 - dense_4_loss: 0.0075 - dense_5_loss: 0.0724 - dense_6_loss: 0.3833 - dense_7_loss: 0.0112 - dense_8_loss: 0.4355 - dense_9_loss: 0.9405 - dense_acc: 0.9654 - dense_1_acc: 0.6623 - dense_2_acc: 0.4637 - dense_3_acc: 0.5336 - dense_4_acc: 1.0000 - dense_5_acc: 0.9809 - dense_6_acc: 0.9133 - dense_7_acc: 0.9999 - dense_8_acc: 0.8569 - dense_9_acc: 0.6799 - val_loss: 4.4542 - val_dense_loss: 0.0884 - val_dense_1_loss: 0.7322 - val_dense_2_loss: 1.1456 - val_dense_3_loss: 0.9851 - val_dense_4_loss: 0.0063 - val_dense_5_loss: 0.0539 - val_dense_6_loss: 0.3109 - val_dense_7_loss: 0.0079 - val_dense_8_loss: 0.3485 - val_dense_9_loss: 0.7754 - val_dense_acc: 0.9697 - val_dense_1_acc: 0.6850 - val_dense_2_acc: 0.4592 - val_dense_3_acc: 0.5748 - val_dense_4_acc: 1.0000 - val_dense_5_acc: 0.9838 - val_dense_6_acc: 0.9240 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.8893 - val_dense_9_acc: 0.7490\n",
      "Epoch 4/100\n",
      "400/400 [==============================] - 16s 41ms/step - loss: 4.3111 - dense_loss: 0.0906 - dense_1_loss: 0.7099 - dense_2_loss: 1.1157 - dense_3_loss: 0.9456 - dense_4_loss: 0.0056 - dense_5_loss: 0.0562 - dense_6_loss: 0.3102 - dense_7_loss: 0.0080 - dense_8_loss: 0.3385 - dense_9_loss: 0.7309 - dense_acc: 0.9699 - dense_1_acc: 0.6981 - dense_2_acc: 0.4702 - dense_3_acc: 0.5975 - dense_4_acc: 1.0000 - dense_5_acc: 0.9844 - dense_6_acc: 0.9266 - dense_7_acc: 0.9999 - dense_8_acc: 0.8919 - dense_9_acc: 0.7654 - val_loss: 3.9908 - val_dense_loss: 0.0716 - val_dense_1_loss: 0.6722 - val_dense_2_loss: 1.0971 - val_dense_3_loss: 0.8708 - val_dense_4_loss: 0.0043 - val_dense_5_loss: 0.0510 - val_dense_6_loss: 0.2744 - val_dense_7_loss: 0.0062 - val_dense_8_loss: 0.3013 - val_dense_9_loss: 0.6420 - val_dense_acc: 0.9773 - val_dense_1_acc: 0.7236 - val_dense_2_acc: 0.4605 - val_dense_3_acc: 0.6461 - val_dense_4_acc: 1.0000 - val_dense_5_acc: 0.9832 - val_dense_6_acc: 0.9309 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.9000 - val_dense_9_acc: 0.7943\n",
      "Epoch 5/100\n",
      "400/400 [==============================] - 16s 41ms/step - loss: 3.8772 - dense_loss: 0.0750 - dense_1_loss: 0.6457 - dense_2_loss: 1.0671 - dense_3_loss: 0.8531 - dense_4_loss: 0.0044 - dense_5_loss: 0.0495 - dense_6_loss: 0.2715 - dense_7_loss: 0.0062 - dense_8_loss: 0.2936 - dense_9_loss: 0.6111 - dense_acc: 0.9777 - dense_1_acc: 0.7377 - dense_2_acc: 0.4800 - dense_3_acc: 0.6531 - dense_4_acc: 1.0000 - dense_5_acc: 0.9853 - dense_6_acc: 0.9345 - dense_7_acc: 0.9999 - dense_8_acc: 0.9046 - dense_9_acc: 0.8060 - val_loss: 3.6382 - val_dense_loss: 0.0606 - val_dense_1_loss: 0.6077 - val_dense_2_loss: 1.0406 - val_dense_3_loss: 0.7803 - val_dense_4_loss: 0.0038 - val_dense_5_loss: 0.0478 - val_dense_6_loss: 0.2528 - val_dense_7_loss: 0.0051 - val_dense_8_loss: 0.2669 - val_dense_9_loss: 0.5726 - val_dense_acc: 0.9818 - val_dense_1_acc: 0.7615 - val_dense_2_acc: 0.4805 - val_dense_3_acc: 0.6951 - val_dense_4_acc: 1.0000 - val_dense_5_acc: 0.9842 - val_dense_6_acc: 0.9350 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.9129 - val_dense_9_acc: 0.8070\n",
      "Epoch 6/100\n",
      "400/400 [==============================] - 17s 42ms/step - loss: 3.5490 - dense_loss: 0.0622 - dense_1_loss: 0.5846 - dense_2_loss: 1.0174 - dense_3_loss: 0.7654 - dense_4_loss: 0.0035 - dense_5_loss: 0.0451 - dense_6_loss: 0.2473 - dense_7_loss: 0.0053 - dense_8_loss: 0.2673 - dense_9_loss: 0.5510 - dense_acc: 0.9822 - dense_1_acc: 0.7748 - dense_2_acc: 0.5015 - dense_3_acc: 0.7030 - dense_4_acc: 1.0000 - dense_5_acc: 0.9861 - dense_6_acc: 0.9391 - dense_7_acc: 0.9999 - dense_8_acc: 0.9124 - dense_9_acc: 0.8193 - val_loss: 3.3408 - val_dense_loss: 0.0517 - val_dense_1_loss: 0.5458 - val_dense_2_loss: 0.9857 - val_dense_3_loss: 0.7043 - val_dense_4_loss: 0.0033 - val_dense_5_loss: 0.0425 - val_dense_6_loss: 0.2367 - val_dense_7_loss: 0.0043 - val_dense_8_loss: 0.2466 - val_dense_9_loss: 0.5200 - val_dense_acc: 0.9863 - val_dense_1_acc: 0.7951 - val_dense_2_acc: 0.5119 - val_dense_3_acc: 0.7332 - val_dense_4_acc: 1.0000 - val_dense_5_acc: 0.9848 - val_dense_6_acc: 0.9381 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.9213 - val_dense_9_acc: 0.8215\n",
      "Epoch 7/100\n",
      "400/400 [==============================] - 16s 41ms/step - loss: 3.2424 - dense_loss: 0.0549 - dense_1_loss: 0.5244 - dense_2_loss: 0.9569 - dense_3_loss: 0.6854 - dense_4_loss: 0.0031 - dense_5_loss: 0.0430 - dense_6_loss: 0.2302 - dense_7_loss: 0.0046 - dense_8_loss: 0.2435 - dense_9_loss: 0.4964 - dense_acc: 0.9863 - dense_1_acc: 0.8103 - dense_2_acc: 0.5349 - dense_3_acc: 0.7526 - dense_4_acc: 1.0000 - dense_5_acc: 0.9863 - dense_6_acc: 0.9426 - dense_7_acc: 0.9999 - dense_8_acc: 0.9215 - dense_9_acc: 0.8328 - val_loss: 3.0820 - val_dense_loss: 0.0458 - val_dense_1_loss: 0.4906 - val_dense_2_loss: 0.9194 - val_dense_3_loss: 0.6399 - val_dense_4_loss: 0.0024 - val_dense_5_loss: 0.0440 - val_dense_6_loss: 0.2237 - val_dense_7_loss: 0.0035 - val_dense_8_loss: 0.2324 - val_dense_9_loss: 0.4803 - val_dense_acc: 0.9891 - val_dense_1_acc: 0.8252 - val_dense_2_acc: 0.5729 - val_dense_3_acc: 0.7779 - val_dense_4_acc: 1.0000 - val_dense_5_acc: 0.9846 - val_dense_6_acc: 0.9420 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.9250 - val_dense_9_acc: 0.8330\n",
      "Epoch 8/100\n",
      "400/400 [==============================] - 17s 41ms/step - loss: 3.0048 - dense_loss: 0.0504 - dense_1_loss: 0.4778 - dense_2_loss: 0.8968 - dense_3_loss: 0.6241 - dense_4_loss: 0.0028 - dense_5_loss: 0.0432 - dense_6_loss: 0.2179 - dense_7_loss: 0.0039 - dense_8_loss: 0.2274 - dense_9_loss: 0.4606 - dense_acc: 0.9871 - dense_1_acc: 0.8299 - dense_2_acc: 0.5785 - dense_3_acc: 0.7888 - dense_4_acc: 1.0000 - dense_5_acc: 0.9859 - dense_6_acc: 0.9441 - dense_7_acc: 1.0000 - dense_8_acc: 0.9252 - dense_9_acc: 0.8430 - val_loss: 2.8390 - val_dense_loss: 0.0405 - val_dense_1_loss: 0.4474 - val_dense_2_loss: 0.8531 - val_dense_3_loss: 0.5782 - val_dense_4_loss: 0.0025 - val_dense_5_loss: 0.0407 - val_dense_6_loss: 0.2112 - val_dense_7_loss: 0.0037 - val_dense_8_loss: 0.2195 - val_dense_9_loss: 0.4423 - val_dense_acc: 0.9914 - val_dense_1_acc: 0.8432 - val_dense_2_acc: 0.6129 - val_dense_3_acc: 0.8105 - val_dense_4_acc: 1.0000 - val_dense_5_acc: 0.9854 - val_dense_6_acc: 0.9439 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.9287 - val_dense_9_acc: 0.8445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100\n",
      "400/400 [==============================] - 16s 41ms/step - loss: 2.7594 - dense_loss: 0.0462 - dense_1_loss: 0.4316 - dense_2_loss: 0.8235 - dense_3_loss: 0.5620 - dense_4_loss: 0.0025 - dense_5_loss: 0.0405 - dense_6_loss: 0.2127 - dense_7_loss: 0.0036 - dense_8_loss: 0.2119 - dense_9_loss: 0.4248 - dense_acc: 0.9888 - dense_1_acc: 0.8524 - dense_2_acc: 0.6304 - dense_3_acc: 0.8187 - dense_4_acc: 1.0000 - dense_5_acc: 0.9863 - dense_6_acc: 0.9436 - dense_7_acc: 0.9999 - dense_8_acc: 0.9300 - dense_9_acc: 0.8544 - val_loss: 2.6358 - val_dense_loss: 0.0382 - val_dense_1_loss: 0.4125 - val_dense_2_loss: 0.7867 - val_dense_3_loss: 0.5302 - val_dense_4_loss: 0.0025 - val_dense_5_loss: 0.0400 - val_dense_6_loss: 0.2035 - val_dense_7_loss: 0.0029 - val_dense_8_loss: 0.2083 - val_dense_9_loss: 0.4110 - val_dense_acc: 0.9920 - val_dense_1_acc: 0.8592 - val_dense_2_acc: 0.6621 - val_dense_3_acc: 0.8285 - val_dense_4_acc: 1.0000 - val_dense_5_acc: 0.9859 - val_dense_6_acc: 0.9447 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.9338 - val_dense_9_acc: 0.8537\n",
      "Epoch 10/100\n",
      "400/400 [==============================] - 17s 41ms/step - loss: 2.5436 - dense_loss: 0.0444 - dense_1_loss: 0.3983 - dense_2_loss: 0.7561 - dense_3_loss: 0.5113 - dense_4_loss: 0.0025 - dense_5_loss: 0.0391 - dense_6_loss: 0.1965 - dense_7_loss: 0.0033 - dense_8_loss: 0.1987 - dense_9_loss: 0.3935 - dense_acc: 0.9888 - dense_1_acc: 0.8660 - dense_2_acc: 0.6789 - dense_3_acc: 0.8436 - dense_4_acc: 1.0000 - dense_5_acc: 0.9869 - dense_6_acc: 0.9493 - dense_7_acc: 0.9999 - dense_8_acc: 0.9344 - dense_9_acc: 0.8651 - val_loss: 2.4563 - val_dense_loss: 0.0354 - val_dense_1_loss: 0.3846 - val_dense_2_loss: 0.7251 - val_dense_3_loss: 0.4882 - val_dense_4_loss: 0.0022 - val_dense_5_loss: 0.0390 - val_dense_6_loss: 0.1956 - val_dense_7_loss: 0.0026 - val_dense_8_loss: 0.2000 - val_dense_9_loss: 0.3836 - val_dense_acc: 0.9924 - val_dense_1_acc: 0.8715 - val_dense_2_acc: 0.7016 - val_dense_3_acc: 0.8516 - val_dense_4_acc: 0.9998 - val_dense_5_acc: 0.9857 - val_dense_6_acc: 0.9469 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.9350 - val_dense_9_acc: 0.8637\n",
      "Epoch 11/100\n",
      "400/400 [==============================] - 17s 41ms/step - loss: 2.3806 - dense_loss: 0.0402 - dense_1_loss: 0.3722 - dense_2_loss: 0.7005 - dense_3_loss: 0.4746 - dense_4_loss: 0.0021 - dense_5_loss: 0.0383 - dense_6_loss: 0.1932 - dense_7_loss: 0.0029 - dense_8_loss: 0.1914 - dense_9_loss: 0.3651 - dense_acc: 0.9908 - dense_1_acc: 0.8726 - dense_2_acc: 0.7153 - dense_3_acc: 0.8566 - dense_4_acc: 1.0000 - dense_5_acc: 0.9865 - dense_6_acc: 0.9478 - dense_7_acc: 0.9999 - dense_8_acc: 0.9372 - dense_9_acc: 0.8738 - val_loss: 2.2974 - val_dense_loss: 0.0332 - val_dense_1_loss: 0.3633 - val_dense_2_loss: 0.6748 - val_dense_3_loss: 0.4503 - val_dense_4_loss: 0.0019 - val_dense_5_loss: 0.0373 - val_dense_6_loss: 0.1864 - val_dense_7_loss: 0.0024 - val_dense_8_loss: 0.1910 - val_dense_9_loss: 0.3568 - val_dense_acc: 0.9924 - val_dense_1_acc: 0.8814 - val_dense_2_acc: 0.7318 - val_dense_3_acc: 0.8666 - val_dense_4_acc: 1.0000 - val_dense_5_acc: 0.9867 - val_dense_6_acc: 0.9482 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.9373 - val_dense_9_acc: 0.8748\n",
      "Epoch 12/100\n",
      "400/400 [==============================] - 17s 41ms/step - loss: 2.2232 - dense_loss: 0.0372 - dense_1_loss: 0.3515 - dense_2_loss: 0.6431 - dense_3_loss: 0.4387 - dense_4_loss: 0.0020 - dense_5_loss: 0.0374 - dense_6_loss: 0.1824 - dense_7_loss: 0.0027 - dense_8_loss: 0.1832 - dense_9_loss: 0.3451 - dense_acc: 0.9910 - dense_1_acc: 0.8841 - dense_2_acc: 0.7477 - dense_3_acc: 0.8720 - dense_4_acc: 1.0000 - dense_5_acc: 0.9867 - dense_6_acc: 0.9513 - dense_7_acc: 0.9999 - dense_8_acc: 0.9393 - dense_9_acc: 0.8803 - val_loss: 2.1734 - val_dense_loss: 0.0312 - val_dense_1_loss: 0.3473 - val_dense_2_loss: 0.6348 - val_dense_3_loss: 0.4274 - val_dense_4_loss: 0.0021 - val_dense_5_loss: 0.0367 - val_dense_6_loss: 0.1810 - val_dense_7_loss: 0.0023 - val_dense_8_loss: 0.1798 - val_dense_9_loss: 0.3308 - val_dense_acc: 0.9936 - val_dense_1_acc: 0.8867 - val_dense_2_acc: 0.7557 - val_dense_3_acc: 0.8684 - val_dense_4_acc: 1.0000 - val_dense_5_acc: 0.9859 - val_dense_6_acc: 0.9479 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.9422 - val_dense_9_acc: 0.8826\n",
      "Epoch 13/100\n",
      "400/400 [==============================] - 16s 41ms/step - loss: 2.0778 - dense_loss: 0.0351 - dense_1_loss: 0.3302 - dense_2_loss: 0.5965 - dense_3_loss: 0.4102 - dense_4_loss: 0.0019 - dense_5_loss: 0.0374 - dense_6_loss: 0.1730 - dense_7_loss: 0.0024 - dense_8_loss: 0.1740 - dense_9_loss: 0.3169 - dense_acc: 0.9919 - dense_1_acc: 0.8917 - dense_2_acc: 0.7773 - dense_3_acc: 0.8801 - dense_4_acc: 1.0000 - dense_5_acc: 0.9872 - dense_6_acc: 0.9536 - dense_7_acc: 1.0000 - dense_8_acc: 0.9447 - dense_9_acc: 0.8945 - val_loss: 2.0393 - val_dense_loss: 0.0294 - val_dense_1_loss: 0.3279 - val_dense_2_loss: 0.5865 - val_dense_3_loss: 0.3983 - val_dense_4_loss: 0.0016 - val_dense_5_loss: 0.0353 - val_dense_6_loss: 0.1772 - val_dense_7_loss: 0.0018 - val_dense_8_loss: 0.1719 - val_dense_9_loss: 0.3095 - val_dense_acc: 0.9937 - val_dense_1_acc: 0.8943 - val_dense_2_acc: 0.7795 - val_dense_3_acc: 0.8775 - val_dense_4_acc: 1.0000 - val_dense_5_acc: 0.9887 - val_dense_6_acc: 0.9484 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.9453 - val_dense_9_acc: 0.8945\n",
      "Epoch 14/100\n",
      "400/400 [==============================] - 16s 41ms/step - loss: 1.9759 - dense_loss: 0.0327 - dense_1_loss: 0.3146 - dense_2_loss: 0.5618 - dense_3_loss: 0.3906 - dense_4_loss: 0.0018 - dense_5_loss: 0.0352 - dense_6_loss: 0.1712 - dense_7_loss: 0.0022 - dense_8_loss: 0.1663 - dense_9_loss: 0.2995 - dense_acc: 0.9926 - dense_1_acc: 0.8963 - dense_2_acc: 0.7950 - dense_3_acc: 0.8858 - dense_4_acc: 1.0000 - dense_5_acc: 0.9882 - dense_6_acc: 0.9523 - dense_7_acc: 1.0000 - dense_8_acc: 0.9472 - dense_9_acc: 0.8997 - val_loss: 1.9393 - val_dense_loss: 0.0278 - val_dense_1_loss: 0.3122 - val_dense_2_loss: 0.5523 - val_dense_3_loss: 0.3796 - val_dense_4_loss: 0.0013 - val_dense_5_loss: 0.0353 - val_dense_6_loss: 0.1718 - val_dense_7_loss: 0.0016 - val_dense_8_loss: 0.1672 - val_dense_9_loss: 0.2902 - val_dense_acc: 0.9941 - val_dense_1_acc: 0.8996 - val_dense_2_acc: 0.7988 - val_dense_3_acc: 0.8857 - val_dense_4_acc: 1.0000 - val_dense_5_acc: 0.9887 - val_dense_6_acc: 0.9504 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.9449 - val_dense_9_acc: 0.9023\n",
      "Epoch 15/100\n",
      "400/400 [==============================] - 16s 40ms/step - loss: 1.8629 - dense_loss: 0.0314 - dense_1_loss: 0.3031 - dense_2_loss: 0.5242 - dense_3_loss: 0.3692 - dense_4_loss: 0.0016 - dense_5_loss: 0.0341 - dense_6_loss: 0.1645 - dense_7_loss: 0.0019 - dense_8_loss: 0.1569 - dense_9_loss: 0.2761 - dense_acc: 0.9929 - dense_1_acc: 0.9027 - dense_2_acc: 0.8150 - dense_3_acc: 0.8926 - dense_4_acc: 1.0000 - dense_5_acc: 0.9878 - dense_6_acc: 0.9548 - dense_7_acc: 1.0000 - dense_8_acc: 0.9501 - dense_9_acc: 0.9100 - val_loss: 1.8470 - val_dense_loss: 0.0267 - val_dense_1_loss: 0.2993 - val_dense_2_loss: 0.5188 - val_dense_3_loss: 0.3644 - val_dense_4_loss: 0.0016 - val_dense_5_loss: 0.0345 - val_dense_6_loss: 0.1661 - val_dense_7_loss: 0.0016 - val_dense_8_loss: 0.1583 - val_dense_9_loss: 0.2758 - val_dense_acc: 0.9943 - val_dense_1_acc: 0.9064 - val_dense_2_acc: 0.8125 - val_dense_3_acc: 0.8875 - val_dense_4_acc: 1.0000 - val_dense_5_acc: 0.9877 - val_dense_6_acc: 0.9498 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.9484 - val_dense_9_acc: 0.9053\n",
      "Epoch 16/100\n",
      "400/400 [==============================] - 16s 39ms/step - loss: 1.7931 - dense_loss: 0.0323 - dense_1_loss: 0.2907 - dense_2_loss: 0.4956 - dense_3_loss: 0.3564 - dense_4_loss: 0.0015 - dense_5_loss: 0.0347 - dense_6_loss: 0.1630 - dense_7_loss: 0.0019 - dense_8_loss: 0.1515 - dense_9_loss: 0.2655 - dense_acc: 0.9927 - dense_1_acc: 0.9074 - dense_2_acc: 0.8321 - dense_3_acc: 0.8933 - dense_4_acc: 1.0000 - dense_5_acc: 0.9882 - dense_6_acc: 0.9552 - dense_7_acc: 0.9999 - dense_8_acc: 0.9515 - dense_9_acc: 0.9141 - val_loss: 1.7687 - val_dense_loss: 0.0256 - val_dense_1_loss: 0.2878 - val_dense_2_loss: 0.4969 - val_dense_3_loss: 0.3485 - val_dense_4_loss: 0.0013 - val_dense_5_loss: 0.0331 - val_dense_6_loss: 0.1626 - val_dense_7_loss: 0.0015 - val_dense_8_loss: 0.1519 - val_dense_9_loss: 0.2594 - val_dense_acc: 0.9945 - val_dense_1_acc: 0.9121 - val_dense_2_acc: 0.8250 - val_dense_3_acc: 0.8908 - val_dense_4_acc: 1.0000 - val_dense_5_acc: 0.9891 - val_dense_6_acc: 0.9498 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.9516 - val_dense_9_acc: 0.9119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100\n",
      "400/400 [==============================] - 16s 40ms/step - loss: 1.6993 - dense_loss: 0.0292 - dense_1_loss: 0.2774 - dense_2_loss: 0.4724 - dense_3_loss: 0.3403 - dense_4_loss: 0.0014 - dense_5_loss: 0.0326 - dense_6_loss: 0.1536 - dense_7_loss: 0.0016 - dense_8_loss: 0.1413 - dense_9_loss: 0.2495 - dense_acc: 0.9935 - dense_1_acc: 0.9127 - dense_2_acc: 0.8399 - dense_3_acc: 0.8996 - dense_4_acc: 1.0000 - dense_5_acc: 0.9882 - dense_6_acc: 0.9580 - dense_7_acc: 0.9999 - dense_8_acc: 0.9553 - dense_9_acc: 0.9199 - val_loss: 1.6919 - val_dense_loss: 0.0247 - val_dense_1_loss: 0.2779 - val_dense_2_loss: 0.4703 - val_dense_3_loss: 0.3358 - val_dense_4_loss: 0.0012 - val_dense_5_loss: 0.0322 - val_dense_6_loss: 0.1586 - val_dense_7_loss: 0.0014 - val_dense_8_loss: 0.1421 - val_dense_9_loss: 0.2478 - val_dense_acc: 0.9947 - val_dense_1_acc: 0.9143 - val_dense_2_acc: 0.8365 - val_dense_3_acc: 0.8945 - val_dense_4_acc: 1.0000 - val_dense_5_acc: 0.9887 - val_dense_6_acc: 0.9529 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.9563 - val_dense_9_acc: 0.9164\n",
      "Epoch 18/100\n",
      "400/400 [==============================] - 16s 41ms/step - loss: 1.6307 - dense_loss: 0.0288 - dense_1_loss: 0.2675 - dense_2_loss: 0.4510 - dense_3_loss: 0.3230 - dense_4_loss: 0.0013 - dense_5_loss: 0.0334 - dense_6_loss: 0.1508 - dense_7_loss: 0.0015 - dense_8_loss: 0.1380 - dense_9_loss: 0.2352 - dense_acc: 0.9934 - dense_1_acc: 0.9164 - dense_2_acc: 0.8495 - dense_3_acc: 0.9054 - dense_4_acc: 1.0000 - dense_5_acc: 0.9880 - dense_6_acc: 0.9572 - dense_7_acc: 0.9999 - dense_8_acc: 0.9567 - dense_9_acc: 0.9253 - val_loss: 1.6300 - val_dense_loss: 0.0238 - val_dense_1_loss: 0.2660 - val_dense_2_loss: 0.4513 - val_dense_3_loss: 0.3281 - val_dense_4_loss: 0.0011 - val_dense_5_loss: 0.0324 - val_dense_6_loss: 0.1530 - val_dense_7_loss: 0.0012 - val_dense_8_loss: 0.1361 - val_dense_9_loss: 0.2369 - val_dense_acc: 0.9949 - val_dense_1_acc: 0.9209 - val_dense_2_acc: 0.8504 - val_dense_3_acc: 0.8973 - val_dense_4_acc: 1.0000 - val_dense_5_acc: 0.9893 - val_dense_6_acc: 0.9551 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.9582 - val_dense_9_acc: 0.9211\n",
      "Epoch 19/100\n",
      "400/400 [==============================] - 16s 40ms/step - loss: 1.5629 - dense_loss: 0.0281 - dense_1_loss: 0.2630 - dense_2_loss: 0.4289 - dense_3_loss: 0.3099 - dense_4_loss: 0.0012 - dense_5_loss: 0.0320 - dense_6_loss: 0.1446 - dense_7_loss: 0.0014 - dense_8_loss: 0.1296 - dense_9_loss: 0.2244 - dense_acc: 0.9932 - dense_1_acc: 0.9199 - dense_2_acc: 0.8614 - dense_3_acc: 0.9092 - dense_4_acc: 1.0000 - dense_5_acc: 0.9882 - dense_6_acc: 0.9603 - dense_7_acc: 1.0000 - dense_8_acc: 0.9597 - dense_9_acc: 0.9306 - val_loss: 1.5716 - val_dense_loss: 0.0234 - val_dense_1_loss: 0.2582 - val_dense_2_loss: 0.4336 - val_dense_3_loss: 0.3124 - val_dense_4_loss: 9.3056e-04 - val_dense_5_loss: 0.0315 - val_dense_6_loss: 0.1526 - val_dense_7_loss: 0.0010 - val_dense_8_loss: 0.1325 - val_dense_9_loss: 0.2254 - val_dense_acc: 0.9945 - val_dense_1_acc: 0.9225 - val_dense_2_acc: 0.8553 - val_dense_3_acc: 0.9041 - val_dense_4_acc: 1.0000 - val_dense_5_acc: 0.9893 - val_dense_6_acc: 0.9521 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.9602 - val_dense_9_acc: 0.9273\n",
      "Epoch 20/100\n",
      "400/400 [==============================] - 16s 39ms/step - loss: 1.5184 - dense_loss: 0.0279 - dense_1_loss: 0.2527 - dense_2_loss: 0.4136 - dense_3_loss: 0.3055 - dense_4_loss: 0.0011 - dense_5_loss: 0.0319 - dense_6_loss: 0.1440 - dense_7_loss: 0.0012 - dense_8_loss: 0.1238 - dense_9_loss: 0.2167 - dense_acc: 0.9931 - dense_1_acc: 0.9228 - dense_2_acc: 0.8666 - dense_3_acc: 0.9076 - dense_4_acc: 1.0000 - dense_5_acc: 0.9888 - dense_6_acc: 0.9597 - dense_7_acc: 1.0000 - dense_8_acc: 0.9621 - dense_9_acc: 0.9328 - val_loss: 1.5196 - val_dense_loss: 0.0226 - val_dense_1_loss: 0.2485 - val_dense_2_loss: 0.4163 - val_dense_3_loss: 0.3039 - val_dense_4_loss: 9.6698e-04 - val_dense_5_loss: 0.0322 - val_dense_6_loss: 0.1490 - val_dense_7_loss: 0.0010 - val_dense_8_loss: 0.1282 - val_dense_9_loss: 0.2170 - val_dense_acc: 0.9947 - val_dense_1_acc: 0.9262 - val_dense_2_acc: 0.8641 - val_dense_3_acc: 0.9059 - val_dense_4_acc: 1.0000 - val_dense_5_acc: 0.9885 - val_dense_6_acc: 0.9541 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.9602 - val_dense_9_acc: 0.9299\n",
      "Epoch 21/100\n",
      "400/400 [==============================] - 16s 40ms/step - loss: 1.4737 - dense_loss: 0.0285 - dense_1_loss: 0.2486 - dense_2_loss: 0.3946 - dense_3_loss: 0.2923 - dense_4_loss: 0.0010 - dense_5_loss: 0.0304 - dense_6_loss: 0.1444 - dense_7_loss: 0.0012 - dense_8_loss: 0.1222 - dense_9_loss: 0.2104 - dense_acc: 0.9933 - dense_1_acc: 0.9241 - dense_2_acc: 0.8753 - dense_3_acc: 0.9128 - dense_4_acc: 1.0000 - dense_5_acc: 0.9894 - dense_6_acc: 0.9586 - dense_7_acc: 1.0000 - dense_8_acc: 0.9619 - dense_9_acc: 0.9347 - val_loss: 1.4681 - val_dense_loss: 0.0222 - val_dense_1_loss: 0.2409 - val_dense_2_loss: 0.4000 - val_dense_3_loss: 0.2950 - val_dense_4_loss: 9.3013e-04 - val_dense_5_loss: 0.0310 - val_dense_6_loss: 0.1472 - val_dense_7_loss: 9.2351e-04 - val_dense_8_loss: 0.1201 - val_dense_9_loss: 0.2100 - val_dense_acc: 0.9949 - val_dense_1_acc: 0.9281 - val_dense_2_acc: 0.8689 - val_dense_3_acc: 0.9086 - val_dense_4_acc: 1.0000 - val_dense_5_acc: 0.9900 - val_dense_6_acc: 0.9551 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.9654 - val_dense_9_acc: 0.9312\n",
      "Epoch 22/100\n",
      "400/400 [==============================] - 16s 39ms/step - loss: 1.4191 - dense_loss: 0.0263 - dense_1_loss: 0.2327 - dense_2_loss: 0.3849 - dense_3_loss: 0.2815 - dense_4_loss: 9.4582e-04 - dense_5_loss: 0.0308 - dense_6_loss: 0.1407 - dense_7_loss: 0.0011 - dense_8_loss: 0.1195 - dense_9_loss: 0.2006 - dense_acc: 0.9937 - dense_1_acc: 0.9326 - dense_2_acc: 0.8769 - dense_3_acc: 0.9154 - dense_4_acc: 1.0000 - dense_5_acc: 0.9886 - dense_6_acc: 0.9595 - dense_7_acc: 1.0000 - dense_8_acc: 0.9639 - dense_9_acc: 0.9386 - val_loss: 1.4250 - val_dense_loss: 0.0215 - val_dense_1_loss: 0.2340 - val_dense_2_loss: 0.3867 - val_dense_3_loss: 0.2876 - val_dense_4_loss: 7.7959e-04 - val_dense_5_loss: 0.0302 - val_dense_6_loss: 0.1443 - val_dense_7_loss: 8.8137e-04 - val_dense_8_loss: 0.1180 - val_dense_9_loss: 0.2011 - val_dense_acc: 0.9951 - val_dense_1_acc: 0.9295 - val_dense_2_acc: 0.8754 - val_dense_3_acc: 0.9113 - val_dense_4_acc: 1.0000 - val_dense_5_acc: 0.9900 - val_dense_6_acc: 0.9547 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.9639 - val_dense_9_acc: 0.9342\n",
      "Epoch 23/100\n",
      "400/400 [==============================] - 16s 40ms/step - loss: 1.3691 - dense_loss: 0.0266 - dense_1_loss: 0.2308 - dense_2_loss: 0.3698 - dense_3_loss: 0.2732 - dense_4_loss: 8.9424e-04 - dense_5_loss: 0.0293 - dense_6_loss: 0.1390 - dense_7_loss: 0.0011 - dense_8_loss: 0.1086 - dense_9_loss: 0.1898 - dense_acc: 0.9937 - dense_1_acc: 0.9319 - dense_2_acc: 0.8820 - dense_3_acc: 0.9181 - dense_4_acc: 1.0000 - dense_5_acc: 0.9894 - dense_6_acc: 0.9598 - dense_7_acc: 0.9999 - dense_8_acc: 0.9678 - dense_9_acc: 0.9430 - val_loss: 1.3848 - val_dense_loss: 0.0213 - val_dense_1_loss: 0.2282 - val_dense_2_loss: 0.3746 - val_dense_3_loss: 0.2789 - val_dense_4_loss: 7.7106e-04 - val_dense_5_loss: 0.0304 - val_dense_6_loss: 0.1412 - val_dense_7_loss: 9.3804e-04 - val_dense_8_loss: 0.1131 - val_dense_9_loss: 0.1955 - val_dense_acc: 0.9953 - val_dense_1_acc: 0.9328 - val_dense_2_acc: 0.8797 - val_dense_3_acc: 0.9127 - val_dense_4_acc: 1.0000 - val_dense_5_acc: 0.9895 - val_dense_6_acc: 0.9561 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.9676 - val_dense_9_acc: 0.9361\n",
      "Epoch 24/100\n",
      "400/400 [==============================] - 16s 39ms/step - loss: 1.3237 - dense_loss: 0.0251 - dense_1_loss: 0.2219 - dense_2_loss: 0.3556 - dense_3_loss: 0.2682 - dense_4_loss: 9.0236e-04 - dense_5_loss: 0.0284 - dense_6_loss: 0.1348 - dense_7_loss: 0.0010 - dense_8_loss: 0.1049 - dense_9_loss: 0.1828 - dense_acc: 0.9937 - dense_1_acc: 0.9362 - dense_2_acc: 0.8882 - dense_3_acc: 0.9213 - dense_4_acc: 1.0000 - dense_5_acc: 0.9899 - dense_6_acc: 0.9611 - dense_7_acc: 1.0000 - dense_8_acc: 0.9687 - dense_9_acc: 0.9446 - val_loss: 1.3495 - val_dense_loss: 0.0206 - val_dense_1_loss: 0.2220 - val_dense_2_loss: 0.3631 - val_dense_3_loss: 0.2711 - val_dense_4_loss: 7.3496e-04 - val_dense_5_loss: 0.0304 - val_dense_6_loss: 0.1389 - val_dense_7_loss: 9.2552e-04 - val_dense_8_loss: 0.1118 - val_dense_9_loss: 0.1897 - val_dense_acc: 0.9955 - val_dense_1_acc: 0.9363 - val_dense_2_acc: 0.8854 - val_dense_3_acc: 0.9154 - val_dense_4_acc: 1.0000 - val_dense_5_acc: 0.9900 - val_dense_6_acc: 0.9572 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.9676 - val_dense_9_acc: 0.9396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100\n",
      "400/400 [==============================] - 16s 40ms/step - loss: 1.2954 - dense_loss: 0.0249 - dense_1_loss: 0.2196 - dense_2_loss: 0.3453 - dense_3_loss: 0.2619 - dense_4_loss: 7.7910e-04 - dense_5_loss: 0.0292 - dense_6_loss: 0.1314 - dense_7_loss: 9.3120e-04 - dense_8_loss: 0.1037 - dense_9_loss: 0.1777 - dense_acc: 0.9941 - dense_1_acc: 0.9371 - dense_2_acc: 0.8916 - dense_3_acc: 0.9216 - dense_4_acc: 1.0000 - dense_5_acc: 0.9895 - dense_6_acc: 0.9620 - dense_7_acc: 1.0000 - dense_8_acc: 0.9681 - dense_9_acc: 0.9464 - val_loss: 1.3143 - val_dense_loss: 0.0199 - val_dense_1_loss: 0.2160 - val_dense_2_loss: 0.3531 - val_dense_3_loss: 0.2671 - val_dense_4_loss: 6.0930e-04 - val_dense_5_loss: 0.0296 - val_dense_6_loss: 0.1380 - val_dense_7_loss: 7.4367e-04 - val_dense_8_loss: 0.1054 - val_dense_9_loss: 0.1840 - val_dense_acc: 0.9957 - val_dense_1_acc: 0.9377 - val_dense_2_acc: 0.8904 - val_dense_3_acc: 0.9162 - val_dense_4_acc: 1.0000 - val_dense_5_acc: 0.9902 - val_dense_6_acc: 0.9563 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.9697 - val_dense_9_acc: 0.9404\n",
      "Epoch 26/100\n",
      "400/400 [==============================] - 16s 40ms/step - loss: 1.2659 - dense_loss: 0.0237 - dense_1_loss: 0.2116 - dense_2_loss: 0.3322 - dense_3_loss: 0.2575 - dense_4_loss: 7.5929e-04 - dense_5_loss: 0.0286 - dense_6_loss: 0.1314 - dense_7_loss: 9.2875e-04 - dense_8_loss: 0.1021 - dense_9_loss: 0.1772 - dense_acc: 0.9944 - dense_1_acc: 0.9398 - dense_2_acc: 0.8960 - dense_3_acc: 0.9228 - dense_4_acc: 1.0000 - dense_5_acc: 0.9901 - dense_6_acc: 0.9618 - dense_7_acc: 1.0000 - dense_8_acc: 0.9699 - dense_9_acc: 0.9468 - val_loss: 1.2833 - val_dense_loss: 0.0199 - val_dense_1_loss: 0.2110 - val_dense_2_loss: 0.3425 - val_dense_3_loss: 0.2602 - val_dense_4_loss: 6.4460e-04 - val_dense_5_loss: 0.0300 - val_dense_6_loss: 0.1372 - val_dense_7_loss: 6.9116e-04 - val_dense_8_loss: 0.1024 - val_dense_9_loss: 0.1788 - val_dense_acc: 0.9957 - val_dense_1_acc: 0.9414 - val_dense_2_acc: 0.8893 - val_dense_3_acc: 0.9201 - val_dense_4_acc: 1.0000 - val_dense_5_acc: 0.9893 - val_dense_6_acc: 0.9568 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.9697 - val_dense_9_acc: 0.9430\n",
      "Epoch 27/100\n",
      "400/400 [==============================] - 16s 40ms/step - loss: 1.2363 - dense_loss: 0.0242 - dense_1_loss: 0.2081 - dense_2_loss: 0.3249 - dense_3_loss: 0.2488 - dense_4_loss: 7.0975e-04 - dense_5_loss: 0.0287 - dense_6_loss: 0.1299 - dense_7_loss: 8.8585e-04 - dense_8_loss: 0.0986 - dense_9_loss: 0.1715 - dense_acc: 0.9939 - dense_1_acc: 0.9406 - dense_2_acc: 0.8991 - dense_3_acc: 0.9233 - dense_4_acc: 1.0000 - dense_5_acc: 0.9895 - dense_6_acc: 0.9626 - dense_7_acc: 0.9999 - dense_8_acc: 0.9704 - dense_9_acc: 0.9505 - val_loss: 1.2498 - val_dense_loss: 0.0193 - val_dense_1_loss: 0.2043 - val_dense_2_loss: 0.3308 - val_dense_3_loss: 0.2553 - val_dense_4_loss: 6.0156e-04 - val_dense_5_loss: 0.0293 - val_dense_6_loss: 0.1351 - val_dense_7_loss: 7.0192e-04 - val_dense_8_loss: 0.0999 - val_dense_9_loss: 0.1744 - val_dense_acc: 0.9959 - val_dense_1_acc: 0.9412 - val_dense_2_acc: 0.8951 - val_dense_3_acc: 0.9199 - val_dense_4_acc: 1.0000 - val_dense_5_acc: 0.9898 - val_dense_6_acc: 0.9582 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.9717 - val_dense_9_acc: 0.9447\n",
      "Epoch 28/100\n",
      "400/400 [==============================] - 16s 39ms/step - loss: 1.1900 - dense_loss: 0.0233 - dense_1_loss: 0.1977 - dense_2_loss: 0.3117 - dense_3_loss: 0.2412 - dense_4_loss: 6.8906e-04 - dense_5_loss: 0.0269 - dense_6_loss: 0.1276 - dense_7_loss: 8.3960e-04 - dense_8_loss: 0.0979 - dense_9_loss: 0.1621 - dense_acc: 0.9941 - dense_1_acc: 0.9441 - dense_2_acc: 0.9056 - dense_3_acc: 0.9270 - dense_4_acc: 1.0000 - dense_5_acc: 0.9903 - dense_6_acc: 0.9630 - dense_7_acc: 0.9999 - dense_8_acc: 0.9701 - dense_9_acc: 0.9521 - val_loss: 1.2174 - val_dense_loss: 0.0190 - val_dense_1_loss: 0.2007 - val_dense_2_loss: 0.3217 - val_dense_3_loss: 0.2469 - val_dense_4_loss: 5.8031e-04 - val_dense_5_loss: 0.0290 - val_dense_6_loss: 0.1319 - val_dense_7_loss: 6.9391e-04 - val_dense_8_loss: 0.0978 - val_dense_9_loss: 0.1691 - val_dense_acc: 0.9959 - val_dense_1_acc: 0.9438 - val_dense_2_acc: 0.8994 - val_dense_3_acc: 0.9242 - val_dense_4_acc: 1.0000 - val_dense_5_acc: 0.9896 - val_dense_6_acc: 0.9586 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.9721 - val_dense_9_acc: 0.9445\n",
      "Epoch 29/100\n",
      "400/400 [==============================] - 16s 39ms/step - loss: 1.1824 - dense_loss: 0.0248 - dense_1_loss: 0.2011 - dense_2_loss: 0.3041 - dense_3_loss: 0.2417 - dense_4_loss: 6.6838e-04 - dense_5_loss: 0.0268 - dense_6_loss: 0.1263 - dense_7_loss: 7.8416e-04 - dense_8_loss: 0.0949 - dense_9_loss: 0.1612 - dense_acc: 0.9934 - dense_1_acc: 0.9427 - dense_2_acc: 0.9067 - dense_3_acc: 0.9269 - dense_4_acc: 1.0000 - dense_5_acc: 0.9902 - dense_6_acc: 0.9627 - dense_7_acc: 1.0000 - dense_8_acc: 0.9712 - dense_9_acc: 0.9515 - val_loss: 1.1889 - val_dense_loss: 0.0186 - val_dense_1_loss: 0.1952 - val_dense_2_loss: 0.3129 - val_dense_3_loss: 0.2420 - val_dense_4_loss: 5.2024e-04 - val_dense_5_loss: 0.0293 - val_dense_6_loss: 0.1306 - val_dense_7_loss: 6.0927e-04 - val_dense_8_loss: 0.0940 - val_dense_9_loss: 0.1653 - val_dense_acc: 0.9959 - val_dense_1_acc: 0.9457 - val_dense_2_acc: 0.9025 - val_dense_3_acc: 0.9250 - val_dense_4_acc: 1.0000 - val_dense_5_acc: 0.9900 - val_dense_6_acc: 0.9594 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.9742 - val_dense_9_acc: 0.9488\n",
      "Epoch 30/100\n",
      "400/400 [==============================] - 16s 40ms/step - loss: 1.1511 - dense_loss: 0.0232 - dense_1_loss: 0.1961 - dense_2_loss: 0.2979 - dense_3_loss: 0.2324 - dense_4_loss: 6.0655e-04 - dense_5_loss: 0.0278 - dense_6_loss: 0.1246 - dense_7_loss: 7.0440e-04 - dense_8_loss: 0.0909 - dense_9_loss: 0.1568 - dense_acc: 0.9943 - dense_1_acc: 0.9445 - dense_2_acc: 0.9098 - dense_3_acc: 0.9284 - dense_4_acc: 1.0000 - dense_5_acc: 0.9899 - dense_6_acc: 0.9627 - dense_7_acc: 1.0000 - dense_8_acc: 0.9740 - dense_9_acc: 0.9525 - val_loss: 1.1646 - val_dense_loss: 0.0184 - val_dense_1_loss: 0.1916 - val_dense_2_loss: 0.3046 - val_dense_3_loss: 0.2375 - val_dense_4_loss: 5.2407e-04 - val_dense_5_loss: 0.0290 - val_dense_6_loss: 0.1297 - val_dense_7_loss: 6.0712e-04 - val_dense_8_loss: 0.0916 - val_dense_9_loss: 0.1610 - val_dense_acc: 0.9959 - val_dense_1_acc: 0.9461 - val_dense_2_acc: 0.9076 - val_dense_3_acc: 0.9275 - val_dense_4_acc: 1.0000 - val_dense_5_acc: 0.9895 - val_dense_6_acc: 0.9586 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.9750 - val_dense_9_acc: 0.9512\n",
      "Epoch 31/100\n",
      "400/400 [==============================] - 16s 40ms/step - loss: 1.1220 - dense_loss: 0.0216 - dense_1_loss: 0.1882 - dense_2_loss: 0.2900 - dense_3_loss: 0.2271 - dense_4_loss: 5.8868e-04 - dense_5_loss: 0.0277 - dense_6_loss: 0.1246 - dense_7_loss: 7.1504e-04 - dense_8_loss: 0.0884 - dense_9_loss: 0.1531 - dense_acc: 0.9945 - dense_1_acc: 0.9467 - dense_2_acc: 0.9126 - dense_3_acc: 0.9313 - dense_4_acc: 1.0000 - dense_5_acc: 0.9898 - dense_6_acc: 0.9621 - dense_7_acc: 1.0000 - dense_8_acc: 0.9725 - dense_9_acc: 0.9547 - val_loss: 1.1437 - val_dense_loss: 0.0181 - val_dense_1_loss: 0.1880 - val_dense_2_loss: 0.2987 - val_dense_3_loss: 0.2339 - val_dense_4_loss: 4.9090e-04 - val_dense_5_loss: 0.0286 - val_dense_6_loss: 0.1289 - val_dense_7_loss: 5.9538e-04 - val_dense_8_loss: 0.0898 - val_dense_9_loss: 0.1567 - val_dense_acc: 0.9961 - val_dense_1_acc: 0.9480 - val_dense_2_acc: 0.9076 - val_dense_3_acc: 0.9285 - val_dense_4_acc: 1.0000 - val_dense_5_acc: 0.9893 - val_dense_6_acc: 0.9598 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.9754 - val_dense_9_acc: 0.9508\n",
      "Epoch 32/100\n",
      "400/400 [==============================] - 16s 40ms/step - loss: 1.0978 - dense_loss: 0.0217 - dense_1_loss: 0.1831 - dense_2_loss: 0.2832 - dense_3_loss: 0.2226 - dense_4_loss: 5.8948e-04 - dense_5_loss: 0.0266 - dense_6_loss: 0.1214 - dense_7_loss: 7.3735e-04 - dense_8_loss: 0.0865 - dense_9_loss: 0.1514 - dense_acc: 0.9944 - dense_1_acc: 0.9489 - dense_2_acc: 0.9144 - dense_3_acc: 0.9323 - dense_4_acc: 1.0000 - dense_5_acc: 0.9902 - dense_6_acc: 0.9648 - dense_7_acc: 1.0000 - dense_8_acc: 0.9743 - dense_9_acc: 0.9539 - val_loss: 1.1184 - val_dense_loss: 0.0180 - val_dense_1_loss: 0.1831 - val_dense_2_loss: 0.2899 - val_dense_3_loss: 0.2282 - val_dense_4_loss: 4.8670e-04 - val_dense_5_loss: 0.0289 - val_dense_6_loss: 0.1268 - val_dense_7_loss: 5.4552e-04 - val_dense_8_loss: 0.0877 - val_dense_9_loss: 0.1547 - val_dense_acc: 0.9961 - val_dense_1_acc: 0.9490 - val_dense_2_acc: 0.9086 - val_dense_3_acc: 0.9283 - val_dense_4_acc: 1.0000 - val_dense_5_acc: 0.9896 - val_dense_6_acc: 0.9604 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.9756 - val_dense_9_acc: 0.9514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100\n",
      "400/400 [==============================] - 17s 41ms/step - loss: 1.0601 - dense_loss: 0.0206 - dense_1_loss: 0.1791 - dense_2_loss: 0.2731 - dense_3_loss: 0.2116 - dense_4_loss: 5.7392e-04 - dense_5_loss: 0.0264 - dense_6_loss: 0.1208 - dense_7_loss: 7.0626e-04 - dense_8_loss: 0.0840 - dense_9_loss: 0.1432 - dense_acc: 0.9948 - dense_1_acc: 0.9497 - dense_2_acc: 0.9205 - dense_3_acc: 0.9360 - dense_4_acc: 1.0000 - dense_5_acc: 0.9902 - dense_6_acc: 0.9633 - dense_7_acc: 1.0000 - dense_8_acc: 0.9751 - dense_9_acc: 0.9577 - val_loss: 1.0988 - val_dense_loss: 0.0177 - val_dense_1_loss: 0.1799 - val_dense_2_loss: 0.2836 - val_dense_3_loss: 0.2245 - val_dense_4_loss: 4.2878e-04 - val_dense_5_loss: 0.0288 - val_dense_6_loss: 0.1252 - val_dense_7_loss: 5.5997e-04 - val_dense_8_loss: 0.0869 - val_dense_9_loss: 0.1511 - val_dense_acc: 0.9961 - val_dense_1_acc: 0.9498 - val_dense_2_acc: 0.9141 - val_dense_3_acc: 0.9324 - val_dense_4_acc: 1.0000 - val_dense_5_acc: 0.9893 - val_dense_6_acc: 0.9605 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.9762 - val_dense_9_acc: 0.9527\n",
      "Epoch 34/100\n",
      "400/400 [==============================] - 16s 41ms/step - loss: 1.0542 - dense_loss: 0.0218 - dense_1_loss: 0.1774 - dense_2_loss: 0.2694 - dense_3_loss: 0.2106 - dense_4_loss: 5.2782e-04 - dense_5_loss: 0.0271 - dense_6_loss: 0.1177 - dense_7_loss: 6.9616e-04 - dense_8_loss: 0.0842 - dense_9_loss: 0.1447 - dense_acc: 0.9945 - dense_1_acc: 0.9510 - dense_2_acc: 0.9200 - dense_3_acc: 0.9351 - dense_4_acc: 1.0000 - dense_5_acc: 0.9902 - dense_6_acc: 0.9645 - dense_7_acc: 0.9999 - dense_8_acc: 0.9752 - dense_9_acc: 0.9578 - val_loss: 1.0776 - val_dense_loss: 0.0175 - val_dense_1_loss: 0.1771 - val_dense_2_loss: 0.2765 - val_dense_3_loss: 0.2196 - val_dense_4_loss: 4.9337e-04 - val_dense_5_loss: 0.0282 - val_dense_6_loss: 0.1250 - val_dense_7_loss: 5.5162e-04 - val_dense_8_loss: 0.0848 - val_dense_9_loss: 0.1479 - val_dense_acc: 0.9961 - val_dense_1_acc: 0.9514 - val_dense_2_acc: 0.9146 - val_dense_3_acc: 0.9322 - val_dense_4_acc: 1.0000 - val_dense_5_acc: 0.9891 - val_dense_6_acc: 0.9617 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.9762 - val_dense_9_acc: 0.9549\n",
      "Epoch 35/100\n",
      "400/400 [==============================] - 16s 40ms/step - loss: 1.0246 - dense_loss: 0.0208 - dense_1_loss: 0.1734 - dense_2_loss: 0.2593 - dense_3_loss: 0.2061 - dense_4_loss: 5.4043e-04 - dense_5_loss: 0.0252 - dense_6_loss: 0.1179 - dense_7_loss: 6.4290e-04 - dense_8_loss: 0.0810 - dense_9_loss: 0.1397 - dense_acc: 0.9948 - dense_1_acc: 0.9515 - dense_2_acc: 0.9248 - dense_3_acc: 0.9394 - dense_4_acc: 1.0000 - dense_5_acc: 0.9911 - dense_6_acc: 0.9638 - dense_7_acc: 1.0000 - dense_8_acc: 0.9767 - dense_9_acc: 0.9591 - val_loss: 1.0592 - val_dense_loss: 0.0175 - val_dense_1_loss: 0.1738 - val_dense_2_loss: 0.2719 - val_dense_3_loss: 0.2145 - val_dense_4_loss: 4.5175e-04 - val_dense_5_loss: 0.0283 - val_dense_6_loss: 0.1230 - val_dense_7_loss: 5.6698e-04 - val_dense_8_loss: 0.0829 - val_dense_9_loss: 0.1461 - val_dense_acc: 0.9959 - val_dense_1_acc: 0.9510 - val_dense_2_acc: 0.9176 - val_dense_3_acc: 0.9355 - val_dense_4_acc: 1.0000 - val_dense_5_acc: 0.9900 - val_dense_6_acc: 0.9607 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.9770 - val_dense_9_acc: 0.9545\n",
      "Epoch 36/100\n",
      "400/400 [==============================] - 16s 40ms/step - loss: 1.0062 - dense_loss: 0.0207 - dense_1_loss: 0.1692 - dense_2_loss: 0.2555 - dense_3_loss: 0.2032 - dense_4_loss: 5.2519e-04 - dense_5_loss: 0.0263 - dense_6_loss: 0.1138 - dense_7_loss: 6.6479e-04 - dense_8_loss: 0.0790 - dense_9_loss: 0.1373 - dense_acc: 0.9948 - dense_1_acc: 0.9537 - dense_2_acc: 0.9261 - dense_3_acc: 0.9388 - dense_4_acc: 0.9999 - dense_5_acc: 0.9907 - dense_6_acc: 0.9656 - dense_7_acc: 1.0000 - dense_8_acc: 0.9775 - dense_9_acc: 0.9600 - val_loss: 1.0387 - val_dense_loss: 0.0173 - val_dense_1_loss: 0.1711 - val_dense_2_loss: 0.2658 - val_dense_3_loss: 0.2107 - val_dense_4_loss: 4.1006e-04 - val_dense_5_loss: 0.0271 - val_dense_6_loss: 0.1225 - val_dense_7_loss: 5.0424e-04 - val_dense_8_loss: 0.0808 - val_dense_9_loss: 0.1424 - val_dense_acc: 0.9961 - val_dense_1_acc: 0.9527 - val_dense_2_acc: 0.9207 - val_dense_3_acc: 0.9365 - val_dense_4_acc: 1.0000 - val_dense_5_acc: 0.9895 - val_dense_6_acc: 0.9607 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.9773 - val_dense_9_acc: 0.9557\n",
      "Epoch 37/100\n",
      "400/400 [==============================] - 16s 39ms/step - loss: 0.9801 - dense_loss: 0.0197 - dense_1_loss: 0.1630 - dense_2_loss: 0.2458 - dense_3_loss: 0.1967 - dense_4_loss: 4.9404e-04 - dense_5_loss: 0.0261 - dense_6_loss: 0.1150 - dense_7_loss: 6.0776e-04 - dense_8_loss: 0.0770 - dense_9_loss: 0.1358 - dense_acc: 0.9951 - dense_1_acc: 0.9560 - dense_2_acc: 0.9301 - dense_3_acc: 0.9400 - dense_4_acc: 1.0000 - dense_5_acc: 0.9905 - dense_6_acc: 0.9656 - dense_7_acc: 1.0000 - dense_8_acc: 0.9780 - dense_9_acc: 0.9599 - val_loss: 1.0218 - val_dense_loss: 0.0172 - val_dense_1_loss: 0.1680 - val_dense_2_loss: 0.2594 - val_dense_3_loss: 0.2079 - val_dense_4_loss: 4.6801e-04 - val_dense_5_loss: 0.0274 - val_dense_6_loss: 0.1208 - val_dense_7_loss: 5.2511e-04 - val_dense_8_loss: 0.0798 - val_dense_9_loss: 0.1403 - val_dense_acc: 0.9961 - val_dense_1_acc: 0.9537 - val_dense_2_acc: 0.9223 - val_dense_3_acc: 0.9375 - val_dense_4_acc: 1.0000 - val_dense_5_acc: 0.9902 - val_dense_6_acc: 0.9609 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.9773 - val_dense_9_acc: 0.9559\n",
      "Epoch 38/100\n",
      "400/400 [==============================] - 16s 40ms/step - loss: 0.9666 - dense_loss: 0.0215 - dense_1_loss: 0.1649 - dense_2_loss: 0.2427 - dense_3_loss: 0.1946 - dense_4_loss: 4.4756e-04 - dense_5_loss: 0.0244 - dense_6_loss: 0.1118 - dense_7_loss: 5.6403e-04 - dense_8_loss: 0.0751 - dense_9_loss: 0.1306 - dense_acc: 0.9944 - dense_1_acc: 0.9541 - dense_2_acc: 0.9297 - dense_3_acc: 0.9413 - dense_4_acc: 1.0000 - dense_5_acc: 0.9910 - dense_6_acc: 0.9659 - dense_7_acc: 1.0000 - dense_8_acc: 0.9787 - dense_9_acc: 0.9610 - val_loss: 1.0049 - val_dense_loss: 0.0170 - val_dense_1_loss: 0.1655 - val_dense_2_loss: 0.2545 - val_dense_3_loss: 0.2050 - val_dense_4_loss: 4.0450e-04 - val_dense_5_loss: 0.0264 - val_dense_6_loss: 0.1199 - val_dense_7_loss: 5.0054e-04 - val_dense_8_loss: 0.0786 - val_dense_9_loss: 0.1372 - val_dense_acc: 0.9961 - val_dense_1_acc: 0.9553 - val_dense_2_acc: 0.9250 - val_dense_3_acc: 0.9381 - val_dense_4_acc: 1.0000 - val_dense_5_acc: 0.9898 - val_dense_6_acc: 0.9615 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.9779 - val_dense_9_acc: 0.9576\n",
      "Epoch 39/100\n",
      "400/400 [==============================] - 15s 38ms/step - loss: 0.9650 - dense_loss: 0.0202 - dense_1_loss: 0.1595 - dense_2_loss: 0.2399 - dense_3_loss: 0.1921 - dense_4_loss: 4.1340e-04 - dense_5_loss: 0.0254 - dense_6_loss: 0.1177 - dense_7_loss: 5.3241e-04 - dense_8_loss: 0.0747 - dense_9_loss: 0.1345 - dense_acc: 0.9947 - dense_1_acc: 0.9557 - dense_2_acc: 0.9306 - dense_3_acc: 0.9413 - dense_4_acc: 1.0000 - dense_5_acc: 0.9909 - dense_6_acc: 0.9633 - dense_7_acc: 1.0000 - dense_8_acc: 0.9786 - dense_9_acc: 0.9600 - val_loss: 0.9936 - val_dense_loss: 0.0170 - val_dense_1_loss: 0.1625 - val_dense_2_loss: 0.2506 - val_dense_3_loss: 0.2029 - val_dense_4_loss: 3.8139e-04 - val_dense_5_loss: 0.0272 - val_dense_6_loss: 0.1204 - val_dense_7_loss: 4.8869e-04 - val_dense_8_loss: 0.0772 - val_dense_9_loss: 0.1350 - val_dense_acc: 0.9961 - val_dense_1_acc: 0.9561 - val_dense_2_acc: 0.9275 - val_dense_3_acc: 0.9389 - val_dense_4_acc: 1.0000 - val_dense_5_acc: 0.9898 - val_dense_6_acc: 0.9611 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.9783 - val_dense_9_acc: 0.9568\n",
      "Epoch 40/100\n",
      "400/400 [==============================] - 15s 38ms/step - loss: 0.9459 - dense_loss: 0.0220 - dense_1_loss: 0.1596 - dense_2_loss: 0.2335 - dense_3_loss: 0.1867 - dense_4_loss: 4.2169e-04 - dense_5_loss: 0.0264 - dense_6_loss: 0.1145 - dense_7_loss: 5.8268e-04 - dense_8_loss: 0.0720 - dense_9_loss: 0.1301 - dense_acc: 0.9942 - dense_1_acc: 0.9556 - dense_2_acc: 0.9324 - dense_3_acc: 0.9457 - dense_4_acc: 1.0000 - dense_5_acc: 0.9899 - dense_6_acc: 0.9637 - dense_7_acc: 1.0000 - dense_8_acc: 0.9804 - dense_9_acc: 0.9613 - val_loss: 0.9766 - val_dense_loss: 0.0168 - val_dense_1_loss: 0.1610 - val_dense_2_loss: 0.2452 - val_dense_3_loss: 0.1995 - val_dense_4_loss: 3.9479e-04 - val_dense_5_loss: 0.0267 - val_dense_6_loss: 0.1184 - val_dense_7_loss: 4.5363e-04 - val_dense_8_loss: 0.0749 - val_dense_9_loss: 0.1332 - val_dense_acc: 0.9961 - val_dense_1_acc: 0.9559 - val_dense_2_acc: 0.9297 - val_dense_3_acc: 0.9398 - val_dense_4_acc: 1.0000 - val_dense_5_acc: 0.9900 - val_dense_6_acc: 0.9615 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.9779 - val_dense_9_acc: 0.9572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100\n",
      "400/400 [==============================] - 16s 39ms/step - loss: 0.9313 - dense_loss: 0.0202 - dense_1_loss: 0.1608 - dense_2_loss: 0.2297 - dense_3_loss: 0.1865 - dense_4_loss: 4.0321e-04 - dense_5_loss: 0.0239 - dense_6_loss: 0.1116 - dense_7_loss: 5.0739e-04 - dense_8_loss: 0.0720 - dense_9_loss: 0.1257 - dense_acc: 0.9944 - dense_1_acc: 0.9551 - dense_2_acc: 0.9332 - dense_3_acc: 0.9445 - dense_4_acc: 1.0000 - dense_5_acc: 0.9913 - dense_6_acc: 0.9664 - dense_7_acc: 1.0000 - dense_8_acc: 0.9796 - dense_9_acc: 0.9624 - val_loss: 0.9628 - val_dense_loss: 0.0166 - val_dense_1_loss: 0.1588 - val_dense_2_loss: 0.2410 - val_dense_3_loss: 0.1954 - val_dense_4_loss: 3.1679e-04 - val_dense_5_loss: 0.0262 - val_dense_6_loss: 0.1180 - val_dense_7_loss: 3.6526e-04 - val_dense_8_loss: 0.0744 - val_dense_9_loss: 0.1317 - val_dense_acc: 0.9961 - val_dense_1_acc: 0.9564 - val_dense_2_acc: 0.9287 - val_dense_3_acc: 0.9406 - val_dense_4_acc: 1.0000 - val_dense_5_acc: 0.9906 - val_dense_6_acc: 0.9621 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.9785 - val_dense_9_acc: 0.9572\n",
      "Epoch 42/100\n",
      "400/400 [==============================] - 15s 39ms/step - loss: 0.9109 - dense_loss: 0.0204 - dense_1_loss: 0.1522 - dense_2_loss: 0.2272 - dense_3_loss: 0.1836 - dense_4_loss: 3.7454e-04 - dense_5_loss: 0.0244 - dense_6_loss: 0.1095 - dense_7_loss: 5.0220e-04 - dense_8_loss: 0.0698 - dense_9_loss: 0.1229 - dense_acc: 0.9946 - dense_1_acc: 0.9578 - dense_2_acc: 0.9349 - dense_3_acc: 0.9455 - dense_4_acc: 1.0000 - dense_5_acc: 0.9912 - dense_6_acc: 0.9662 - dense_7_acc: 1.0000 - dense_8_acc: 0.9803 - dense_9_acc: 0.9636 - val_loss: 0.9524 - val_dense_loss: 0.0166 - val_dense_1_loss: 0.1561 - val_dense_2_loss: 0.2355 - val_dense_3_loss: 0.1945 - val_dense_4_loss: 4.0165e-04 - val_dense_5_loss: 0.0272 - val_dense_6_loss: 0.1171 - val_dense_7_loss: 4.7202e-04 - val_dense_8_loss: 0.0742 - val_dense_9_loss: 0.1304 - val_dense_acc: 0.9961 - val_dense_1_acc: 0.9574 - val_dense_2_acc: 0.9316 - val_dense_3_acc: 0.9420 - val_dense_4_acc: 1.0000 - val_dense_5_acc: 0.9900 - val_dense_6_acc: 0.9623 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.9781 - val_dense_9_acc: 0.9582\n",
      "Epoch 43/100\n",
      "400/400 [==============================] - 15s 38ms/step - loss: 0.8953 - dense_loss: 0.0198 - dense_1_loss: 0.1539 - dense_2_loss: 0.2189 - dense_3_loss: 0.1811 - dense_4_loss: 3.7520e-04 - dense_5_loss: 0.0242 - dense_6_loss: 0.1091 - dense_7_loss: 5.2038e-04 - dense_8_loss: 0.0663 - dense_9_loss: 0.1212 - dense_acc: 0.9951 - dense_1_acc: 0.9578 - dense_2_acc: 0.9376 - dense_3_acc: 0.9469 - dense_4_acc: 1.0000 - dense_5_acc: 0.9912 - dense_6_acc: 0.9672 - dense_7_acc: 0.9999 - dense_8_acc: 0.9815 - dense_9_acc: 0.9640 - val_loss: 0.9358 - val_dense_loss: 0.0165 - val_dense_1_loss: 0.1545 - val_dense_2_loss: 0.2318 - val_dense_3_loss: 0.1904 - val_dense_4_loss: 3.5843e-04 - val_dense_5_loss: 0.0260 - val_dense_6_loss: 0.1166 - val_dense_7_loss: 4.6167e-04 - val_dense_8_loss: 0.0726 - val_dense_9_loss: 0.1265 - val_dense_acc: 0.9961 - val_dense_1_acc: 0.9578 - val_dense_2_acc: 0.9318 - val_dense_3_acc: 0.9428 - val_dense_4_acc: 1.0000 - val_dense_5_acc: 0.9904 - val_dense_6_acc: 0.9621 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.9787 - val_dense_9_acc: 0.9598\n",
      "Epoch 44/100\n",
      "400/400 [==============================] - 16s 39ms/step - loss: 0.8889 - dense_loss: 0.0200 - dense_1_loss: 0.1493 - dense_2_loss: 0.2158 - dense_3_loss: 0.1795 - dense_4_loss: 3.7300e-04 - dense_5_loss: 0.0242 - dense_6_loss: 0.1087 - dense_7_loss: 5.4568e-04 - dense_8_loss: 0.0684 - dense_9_loss: 0.1221 - dense_acc: 0.9946 - dense_1_acc: 0.9592 - dense_2_acc: 0.9393 - dense_3_acc: 0.9478 - dense_4_acc: 1.0000 - dense_5_acc: 0.9910 - dense_6_acc: 0.9657 - dense_7_acc: 1.0000 - dense_8_acc: 0.9808 - dense_9_acc: 0.9640 - val_loss: 0.9248 - val_dense_loss: 0.0165 - val_dense_1_loss: 0.1532 - val_dense_2_loss: 0.2277 - val_dense_3_loss: 0.1870 - val_dense_4_loss: 3.9984e-04 - val_dense_5_loss: 0.0265 - val_dense_6_loss: 0.1158 - val_dense_7_loss: 4.4042e-04 - val_dense_8_loss: 0.0715 - val_dense_9_loss: 0.1257 - val_dense_acc: 0.9961 - val_dense_1_acc: 0.9584 - val_dense_2_acc: 0.9348 - val_dense_3_acc: 0.9449 - val_dense_4_acc: 1.0000 - val_dense_5_acc: 0.9902 - val_dense_6_acc: 0.9623 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.9783 - val_dense_9_acc: 0.9588\n",
      "Epoch 45/100\n",
      "400/400 [==============================] - 15s 39ms/step - loss: 0.8860 - dense_loss: 0.0206 - dense_1_loss: 0.1517 - dense_2_loss: 0.2149 - dense_3_loss: 0.1766 - dense_4_loss: 3.8942e-04 - dense_5_loss: 0.0237 - dense_6_loss: 0.1088 - dense_7_loss: 5.0600e-04 - dense_8_loss: 0.0668 - dense_9_loss: 0.1221 - dense_acc: 0.9944 - dense_1_acc: 0.9582 - dense_2_acc: 0.9380 - dense_3_acc: 0.9467 - dense_4_acc: 1.0000 - dense_5_acc: 0.9910 - dense_6_acc: 0.9667 - dense_7_acc: 0.9999 - dense_8_acc: 0.9825 - dense_9_acc: 0.9632 - val_loss: 0.9105 - val_dense_loss: 0.0163 - val_dense_1_loss: 0.1506 - val_dense_2_loss: 0.2234 - val_dense_3_loss: 0.1849 - val_dense_4_loss: 3.8648e-04 - val_dense_5_loss: 0.0256 - val_dense_6_loss: 0.1146 - val_dense_7_loss: 4.4929e-04 - val_dense_8_loss: 0.0703 - val_dense_9_loss: 0.1239 - val_dense_acc: 0.9961 - val_dense_1_acc: 0.9594 - val_dense_2_acc: 0.9359 - val_dense_3_acc: 0.9445 - val_dense_4_acc: 1.0000 - val_dense_5_acc: 0.9902 - val_dense_6_acc: 0.9631 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.9779 - val_dense_9_acc: 0.9596\n",
      "Epoch 46/100\n",
      "400/400 [==============================] - 15s 38ms/step - loss: 0.8620 - dense_loss: 0.0204 - dense_1_loss: 0.1468 - dense_2_loss: 0.2078 - dense_3_loss: 0.1716 - dense_4_loss: 4.1896e-04 - dense_5_loss: 0.0247 - dense_6_loss: 0.1085 - dense_7_loss: 5.1943e-04 - dense_8_loss: 0.0666 - dense_9_loss: 0.1147 - dense_acc: 0.9947 - dense_1_acc: 0.9597 - dense_2_acc: 0.9417 - dense_3_acc: 0.9500 - dense_4_acc: 0.9999 - dense_5_acc: 0.9912 - dense_6_acc: 0.9660 - dense_7_acc: 1.0000 - dense_8_acc: 0.9815 - dense_9_acc: 0.9664 - val_loss: 0.9017 - val_dense_loss: 0.0162 - val_dense_1_loss: 0.1491 - val_dense_2_loss: 0.2206 - val_dense_3_loss: 0.1826 - val_dense_4_loss: 3.4699e-04 - val_dense_5_loss: 0.0262 - val_dense_6_loss: 0.1146 - val_dense_7_loss: 3.9786e-04 - val_dense_8_loss: 0.0693 - val_dense_9_loss: 0.1223 - val_dense_acc: 0.9961 - val_dense_1_acc: 0.9598 - val_dense_2_acc: 0.9375 - val_dense_3_acc: 0.9469 - val_dense_4_acc: 1.0000 - val_dense_5_acc: 0.9906 - val_dense_6_acc: 0.9617 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.9783 - val_dense_9_acc: 0.9600\n",
      "Epoch 47/100\n",
      "400/400 [==============================] - 15s 39ms/step - loss: 0.8549 - dense_loss: 0.0196 - dense_1_loss: 0.1461 - dense_2_loss: 0.2069 - dense_3_loss: 0.1708 - dense_4_loss: 4.0329e-04 - dense_5_loss: 0.0245 - dense_6_loss: 0.1062 - dense_7_loss: 4.7776e-04 - dense_8_loss: 0.0651 - dense_9_loss: 0.1148 - dense_acc: 0.9947 - dense_1_acc: 0.9592 - dense_2_acc: 0.9416 - dense_3_acc: 0.9511 - dense_4_acc: 1.0000 - dense_5_acc: 0.9915 - dense_6_acc: 0.9680 - dense_7_acc: 1.0000 - dense_8_acc: 0.9832 - dense_9_acc: 0.9670 - val_loss: 0.8874 - val_dense_loss: 0.0161 - val_dense_1_loss: 0.1476 - val_dense_2_loss: 0.2161 - val_dense_3_loss: 0.1795 - val_dense_4_loss: 3.0551e-04 - val_dense_5_loss: 0.0253 - val_dense_6_loss: 0.1138 - val_dense_7_loss: 3.4767e-04 - val_dense_8_loss: 0.0685 - val_dense_9_loss: 0.1199 - val_dense_acc: 0.9961 - val_dense_1_acc: 0.9586 - val_dense_2_acc: 0.9389 - val_dense_3_acc: 0.9467 - val_dense_4_acc: 1.0000 - val_dense_5_acc: 0.9908 - val_dense_6_acc: 0.9621 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.9797 - val_dense_9_acc: 0.9619\n",
      "Epoch 48/100\n",
      "400/400 [==============================] - 15s 39ms/step - loss: 0.8472 - dense_loss: 0.0213 - dense_1_loss: 0.1449 - dense_2_loss: 0.2024 - dense_3_loss: 0.1702 - dense_4_loss: 3.4593e-04 - dense_5_loss: 0.0237 - dense_6_loss: 0.1071 - dense_7_loss: 4.8848e-04 - dense_8_loss: 0.0635 - dense_9_loss: 0.1134 - dense_acc: 0.9944 - dense_1_acc: 0.9595 - dense_2_acc: 0.9433 - dense_3_acc: 0.9520 - dense_4_acc: 1.0000 - dense_5_acc: 0.9911 - dense_6_acc: 0.9668 - dense_7_acc: 0.9999 - dense_8_acc: 0.9824 - dense_9_acc: 0.9657 - val_loss: 0.8759 - val_dense_loss: 0.0160 - val_dense_1_loss: 0.1461 - val_dense_2_loss: 0.2127 - val_dense_3_loss: 0.1769 - val_dense_4_loss: 3.3531e-04 - val_dense_5_loss: 0.0255 - val_dense_6_loss: 0.1121 - val_dense_7_loss: 3.9306e-04 - val_dense_8_loss: 0.0669 - val_dense_9_loss: 0.1190 - val_dense_acc: 0.9961 - val_dense_1_acc: 0.9602 - val_dense_2_acc: 0.9400 - val_dense_3_acc: 0.9473 - val_dense_4_acc: 1.0000 - val_dense_5_acc: 0.9908 - val_dense_6_acc: 0.9625 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.9793 - val_dense_9_acc: 0.9619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "400/400 [==============================] - 16s 39ms/step - loss: 0.8289 - dense_loss: 0.0202 - dense_1_loss: 0.1411 - dense_2_loss: 0.1975 - dense_3_loss: 0.1628 - dense_4_loss: 3.1124e-04 - dense_5_loss: 0.0251 - dense_6_loss: 0.1052 - dense_7_loss: 4.2663e-04 - dense_8_loss: 0.0628 - dense_9_loss: 0.1134 - dense_acc: 0.9945 - dense_1_acc: 0.9613 - dense_2_acc: 0.9457 - dense_3_acc: 0.9521 - dense_4_acc: 1.0000 - dense_5_acc: 0.9906 - dense_6_acc: 0.9674 - dense_7_acc: 1.0000 - dense_8_acc: 0.9836 - dense_9_acc: 0.9659 - val_loss: 0.8687 - val_dense_loss: 0.0159 - val_dense_1_loss: 0.1448 - val_dense_2_loss: 0.2102 - val_dense_3_loss: 0.1743 - val_dense_4_loss: 2.9527e-04 - val_dense_5_loss: 0.0258 - val_dense_6_loss: 0.1128 - val_dense_7_loss: 3.4093e-04 - val_dense_8_loss: 0.0661 - val_dense_9_loss: 0.1181 - val_dense_acc: 0.9961 - val_dense_1_acc: 0.9604 - val_dense_2_acc: 0.9412 - val_dense_3_acc: 0.9473 - val_dense_4_acc: 1.0000 - val_dense_5_acc: 0.9902 - val_dense_6_acc: 0.9639 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.9799 - val_dense_9_acc: 0.9625\n",
      "Epoch 50/100\n",
      "400/400 [==============================] - 16s 39ms/step - loss: 0.8127 - dense_loss: 0.0203 - dense_1_loss: 0.1387 - dense_2_loss: 0.1948 - dense_3_loss: 0.1610 - dense_4_loss: 3.1673e-04 - dense_5_loss: 0.0232 - dense_6_loss: 0.1036 - dense_7_loss: 4.2500e-04 - dense_8_loss: 0.0602 - dense_9_loss: 0.1101 - dense_acc: 0.9944 - dense_1_acc: 0.9615 - dense_2_acc: 0.9460 - dense_3_acc: 0.9527 - dense_4_acc: 1.0000 - dense_5_acc: 0.9916 - dense_6_acc: 0.9682 - dense_7_acc: 1.0000 - dense_8_acc: 0.9837 - dense_9_acc: 0.9671 - val_loss: 0.8575 - val_dense_loss: 0.0159 - val_dense_1_loss: 0.1431 - val_dense_2_loss: 0.2065 - val_dense_3_loss: 0.1725 - val_dense_4_loss: 3.1292e-04 - val_dense_5_loss: 0.0252 - val_dense_6_loss: 0.1115 - val_dense_7_loss: 3.7320e-04 - val_dense_8_loss: 0.0659 - val_dense_9_loss: 0.1162 - val_dense_acc: 0.9961 - val_dense_1_acc: 0.9604 - val_dense_2_acc: 0.9424 - val_dense_3_acc: 0.9484 - val_dense_4_acc: 1.0000 - val_dense_5_acc: 0.9906 - val_dense_6_acc: 0.9619 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.9805 - val_dense_9_acc: 0.9633\n",
      "Epoch 51/100\n",
      "400/400 [==============================] - 15s 39ms/step - loss: 0.8180 - dense_loss: 0.0195 - dense_1_loss: 0.1426 - dense_2_loss: 0.1930 - dense_3_loss: 0.1628 - dense_4_loss: 3.3499e-04 - dense_5_loss: 0.0234 - dense_6_loss: 0.1013 - dense_7_loss: 4.5715e-04 - dense_8_loss: 0.0622 - dense_9_loss: 0.1125 - dense_acc: 0.9949 - dense_1_acc: 0.9600 - dense_2_acc: 0.9459 - dense_3_acc: 0.9529 - dense_4_acc: 1.0000 - dense_5_acc: 0.9916 - dense_6_acc: 0.9697 - dense_7_acc: 0.9999 - dense_8_acc: 0.9819 - dense_9_acc: 0.9665 - val_loss: 0.8473 - val_dense_loss: 0.0158 - val_dense_1_loss: 0.1417 - val_dense_2_loss: 0.2030 - val_dense_3_loss: 0.1711 - val_dense_4_loss: 3.0113e-04 - val_dense_5_loss: 0.0250 - val_dense_6_loss: 0.1109 - val_dense_7_loss: 3.4532e-04 - val_dense_8_loss: 0.0646 - val_dense_9_loss: 0.1146 - val_dense_acc: 0.9961 - val_dense_1_acc: 0.9602 - val_dense_2_acc: 0.9426 - val_dense_3_acc: 0.9484 - val_dense_4_acc: 1.0000 - val_dense_5_acc: 0.9910 - val_dense_6_acc: 0.9627 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.9805 - val_dense_9_acc: 0.9637\n",
      "Epoch 52/100\n",
      "400/400 [==============================] - 15s 38ms/step - loss: 0.7908 - dense_loss: 0.0182 - dense_1_loss: 0.1342 - dense_2_loss: 0.1900 - dense_3_loss: 0.1556 - dense_4_loss: 3.0949e-04 - dense_5_loss: 0.0222 - dense_6_loss: 0.1005 - dense_7_loss: 4.7729e-04 - dense_8_loss: 0.0604 - dense_9_loss: 0.1089 - dense_acc: 0.9951 - dense_1_acc: 0.9631 - dense_2_acc: 0.9461 - dense_3_acc: 0.9554 - dense_4_acc: 1.0000 - dense_5_acc: 0.9915 - dense_6_acc: 0.9682 - dense_7_acc: 0.9999 - dense_8_acc: 0.9835 - dense_9_acc: 0.9676 - val_loss: 0.8393 - val_dense_loss: 0.0158 - val_dense_1_loss: 0.1403 - val_dense_2_loss: 0.2007 - val_dense_3_loss: 0.1695 - val_dense_4_loss: 3.6315e-04 - val_dense_5_loss: 0.0247 - val_dense_6_loss: 0.1101 - val_dense_7_loss: 3.7001e-04 - val_dense_8_loss: 0.0636 - val_dense_9_loss: 0.1139 - val_dense_acc: 0.9961 - val_dense_1_acc: 0.9607 - val_dense_2_acc: 0.9453 - val_dense_3_acc: 0.9488 - val_dense_4_acc: 1.0000 - val_dense_5_acc: 0.9910 - val_dense_6_acc: 0.9627 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.9807 - val_dense_9_acc: 0.9637\n",
      "Epoch 53/100\n",
      " 75/400 [====>.........................] - ETA: 11s - loss: 0.7631 - dense_loss: 0.0169 - dense_1_loss: 0.1294 - dense_2_loss: 0.1826 - dense_3_loss: 0.1421 - dense_4_loss: 2.7944e-04 - dense_5_loss: 0.0232 - dense_6_loss: 0.1003 - dense_7_loss: 4.3098e-04 - dense_8_loss: 0.0598 - dense_9_loss: 0.1080 - dense_acc: 0.9957 - dense_1_acc: 0.9627 - dense_2_acc: 0.9480 - dense_3_acc: 0.9599 - dense_4_acc: 1.0000 - dense_5_acc: 0.9916 - dense_6_acc: 0.9684 - dense_7_acc: 1.0000 - dense_8_acc: 0.9838 - dense_9_acc: 0.9676"
     ]
    }
   ],
   "source": [
    "model.compile( \n",
    "    optimizer=Adam(lr=0.005, decay=0.01),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['acc'] \n",
    ")\n",
    "\n",
    "s0 = np.zeros((m, n_s))\n",
    "c0 = np.zeros((m, n_s))\n",
    "\n",
    "Y = list(Y.swapaxes(0,1))\n",
    "Yt = list(Yt.swapaxes(0,1))\n",
    "\n",
    "history = model.fit([X, s0, c0], Y, epochs=100, \n",
    "                    validation_data=([Xt,np.zeros((t, n_s)),np.zeros((t, n_s))],Yt), \n",
    "                    batch_size=BATCH_SIZE, verbose=1)\n",
    "\n",
    "model.save_weights('attention_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24707bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('attention_weights.h5')\n",
    "def getTranslation(date,model):\n",
    "  date = date.lower().replace(',','')\n",
    "  source = np.array(string_to_ohe(date, Tx, human_vocab)[0])\n",
    "  source = np.expand_dims(source,axis=0)\n",
    "  prediction = np.array(model.predict([source, s0, c0]))\n",
    "  prediction = np.squeeze(prediction.swapaxes(0,1))\n",
    "  return output_to_date(prediction,machine_vocab)\n",
    "\n",
    "EXAMPLES = ['3 May 1979', '5 April 09', '21th of August 2016', 'Tue 10 Jul 2007', 'Saturday May 9 2018', 'March 3 2001', 'March 3rd 2001', \n",
    "            '1 March 2001','jun 10 2017','11/07/2002']\n",
    "\n",
    "for example in EXAMPLES:\n",
    "    print(f\"{example} -> {getTranslation(example,model)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow-2.4-cuda11] *",
   "language": "python",
   "name": "conda-env-tensorflow-2.4-cuda11-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
