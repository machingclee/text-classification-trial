{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers\n",
    "\n",
    "We start off by importing the following important layers\n",
    "\n",
    "- **LSTM (Long Short-Term Memory) layer.** A sequential model that learn feature from a series of data:\n",
    "<img width=\"550\" src=\"./LSTM-model.png\">\n",
    "\n",
    "    In our model we are just interested in the last hidden state $h_{699}$. Occationally we also create model that consumes all hidden states ($h_0, \\dots, h_{699}$), for example, attention model (that implements **teacher forcing**) for machine translation or data auto correction.\n",
    "    \n",
    "\n",
    "- **Relu-activation layer.** One of the common layers that provide non-linearity to the network (without activation, a neural network is simply an affine transform which work nothing better than a single layer network)\n",
    "\n",
    "\n",
    "\n",
    "- **Softmax-activation layer.** Common top layer of a network for multi-classification problem since it provides nice computational formula for \"computing weight\" in order to update learning parameter of its previous layer. In other words, it makes the process of ***back-propagation*** simple)\n",
    "\n",
    "\n",
    "- **(Word) Embedding layer.** We will create our own embedding layer using pretrained weights (this process is called **transfer-learning**) instead of learning another one in our network. \n",
    "\n",
    "\n",
    "- **BatchNormalization layer.** It can, by experiment, increase numerical stability in the training process.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "from tensorflow.keras.layers import LSTM, Activation, Dense, Dropout, Input, BatchNormalization, Embedding\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import string\n",
    "import re\n",
    "\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"]=\"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_business = os.path.sep.join([\"data_set\",\"bbc\",\"business\"])\n",
    "bbc = os.path.sep.join([\"data_set\",\"bbc\"]) \n",
    "WORD_EMBEDDING_DIMENSION = 50\n",
    "MAX_VOCAB_SIZE = 10000\n",
    "MAX_LENGTH = 500\n",
    "NUM_CLASSES = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare our Training data as a Python Array Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510 files in data_set\\bbc\\business have been loaded\n",
      "386 files in data_set\\bbc\\entertainment have been loaded\n",
      "417 files in data_set\\bbc\\politics have been loaded\n",
      "511 files in data_set\\bbc\\sport have been loaded\n",
      "401 files in data_set\\bbc\\tech have been loaded\n"
     ]
    }
   ],
   "source": [
    "contents = []\n",
    "labels = []\n",
    "\n",
    "def remove_punctuation(paragraph):\n",
    "    for punc in string.punctuation:\n",
    "        paragraph = paragraph.replace(punc,\"\")\n",
    "    return paragraph\n",
    "\n",
    "def preprocess_data(folder_path):\n",
    "    for i, (dir_path, dir_names, file_names) in enumerate(os.walk(folder_path)):\n",
    "        if dir_path != os.path.sep.join([\"data_set\",\"bbc\"]):\n",
    "            print(f\"{len(file_names)} files in {dir_path} have been loaded\")\n",
    "            for file_name in file_names:\n",
    "                file_path = os.path.sep.join([dir_path, file_name])\n",
    "                category = file_path.split(os.path.sep)[-2]\n",
    "                with open(file_path, \"r\", encoding=\"ISO-8859-1\") as f:\n",
    "                    content = f.read().strip()\n",
    "                    content = remove_punctuation(content)\n",
    "                    content = re.sub(r\"(\\n)+\", \" \", content)\n",
    "                    content = content.lower()\n",
    "                    \n",
    "                    contents.append(content)\n",
    "                    labels.append(category)\n",
    "                    \n",
    "preprocess_data(bbc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand a bit more About our Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have total of 2225 training data\n",
      "1764 of paragraph has number of words less than 500\n",
      "1982 of paragraph has number of words less than 600\n",
      "2095 of paragraph has number of words less than 700\n",
      "2146 of paragraph has number of words less than 800\n",
      "2191 of paragraph has number of words less than 900\n",
      "2203 of paragraph has number of words less than 1000\n",
      "2209 of paragraph has number of words less than 1100\n",
      "2210 of paragraph has number of words less than 1200\n",
      "2212 of paragraph has number of words less than 1300\n",
      "2216 of paragraph has number of words less than 1400\n",
      "2216 of paragraph has number of words less than 1500\n",
      "2217 of paragraph has number of words less than 1600\n",
      "max number of words: 4416\n",
      "min number of words: 89\n",
      "number of words: 851028\n",
      "average number of words: 382\n"
     ]
    }
   ],
   "source": [
    "print(f\"we have total of {len(contents)} training data\")\n",
    "\n",
    "nums=np.array([len(content.split()) for content in contents])\n",
    "\n",
    "max_num_of_words = np.max(nums)\n",
    "min_num_of_words = np.min(nums)\n",
    "total_num_of_words = np.sum(nums)\n",
    "average_num_of_words = total_num_of_words//len(contents)\n",
    "\n",
    "for threshold in np.arange(500, 1601, 100):\n",
    "    print(f\"{len([num for num in nums if num < threshold])} of paragraph has number of words less than {threshold}\")\n",
    "\n",
    "print(f\"max number of words: {max_num_of_words}\")\n",
    "print(f\"min number of words: {min_num_of_words}\")\n",
    "print(f\"number of words: {total_num_of_words}\")\n",
    "print(f\"average number of words: {average_num_of_words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split our dataset into training ones and testing/validation ones. \n",
    "\n",
    "The validation dataset is used to test whether or not our prediction model can \"generalize\" to data that the model has never seen. It can happen that our trained model performs very well on training dataset but works poorly to new data. This phenomenon is called **over-fitting**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(contents, labels, test_size=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Dataset to fit the Model\n",
    "Since the toppest layer in our network, the softmax-activation layer, takes a batch of data and returns a batch of vectors that represent probabilities, we encode our label (as a string) into an array with only one non-zero entry for training purpose (the model learn the true answer and adjust its training weight)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelBinarizer = LabelBinarizer()\n",
    "Y_train = labelBinarizer.fit_transform(Y_train)\n",
    "Y_test = labelBinarizer.transform(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer and Embedding Layer\n",
    "\n",
    "We will not feed our model by simply the string of whole paragraph. Each word in a paragraph does carry meaning, we transform each word into a vector whose positional weight does carry meaning. What we will do:\n",
    "\n",
    "$$\\text{word} \\mapsto  \\underbrace{\\overbrace{\\text{word_to_index}}^{\\large \\text{tokenizer}}(\\text{word})}_{\\Large \\in \\, \\mathbb N} \\mapsto  \\underbrace{\\text{embedding}(\\text{word_to_index}(\\text{word}))}_{\\Large \\in \\,\\mathbb R^{50}} $$\n",
    "\n",
    "We will be defining our embedding matrix which takes an integer into a vector (array) of length 50. The term **matrix** here is merely a numpy array and is not really a mathematical object that turns column vectors into another column vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
    "\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "training_word_to_index = tokenizer.word_index\n",
    "\n",
    "sequences_train = tokenizer.texts_to_sequences(X_train)\n",
    "sequences_test =  tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_train = np.array(sequence.pad_sequences(sequences_train, maxlen=MAX_LENGTH, padding='post'))\n",
    "X_test = np.array(sequence.pad_sequences(sequences_test, maxlen=MAX_LENGTH, padding='post'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Embedding Layer Using Pretrained Weight\n",
    "\n",
    "Note that our matrix is just based on our training set, we are not interested in any other words outside of the scope of our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word vectors...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "def define_embedding_layer():\n",
    "    print(\"Loading word vectors...\")\n",
    "    word_to_vec = {}\n",
    "    embedding_file_path = os.path.sep.join([\"word_embedding\", \"glove.6B.{}d.txt\".format(WORD_EMBEDDING_DIMENSION)])\n",
    "    with open(embedding_file_path, encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vec = np.array(values[1:], dtype=\"float32\")\n",
    "            word_to_vec[word] = vec\n",
    "    \n",
    "    vocab_size = max(\n",
    "        MAX_VOCAB_SIZE,\n",
    "        len(training_word_to_index) + 1\n",
    "    )\n",
    "    embedding_matrix = np.zeros((vocab_size, WORD_EMBEDDING_DIMENSION))\n",
    "\n",
    "    # for embedding matrix, we are just interested in words in our training set:\n",
    "    for word, index in training_word_to_index.items():\n",
    "        word_vec = word_to_vec.get(word)\n",
    "        if word_vec is not None:\n",
    "            embedding_matrix[index] = word_vec\n",
    "\n",
    "    training_word_embedding_layer = Embedding(\n",
    "        vocab_size,\n",
    "        WORD_EMBEDDING_DIMENSION,\n",
    "        weights=[embedding_matrix],\n",
    "        input_length=MAX_LENGTH\n",
    "    )\n",
    "    \n",
    "    print(\"Done!\")\n",
    "    return training_word_embedding_layer\n",
    "\n",
    "training_word_embedding_layer = define_embedding_layer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of Transformed Training data that will be fed into LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3038 1215 1037    6 1849  812 1850 3038 2124    5 1037 2037  520    6\n",
      " 1849    6   30   64 1851 9161  133   15  151 2216 2572 1110   20    1\n",
      "  999 1538 3038  126  379    3 5593 3039 1069    2  138    1  670   20\n",
      "    1 2936  566  212   15  124 4004   25    5  884  235    6    1  155\n",
      "  670    2  521 6869 4336    4 3310   30  297    3    4 1199   41  109\n",
      "  737    3  446 5951 2037   76  216    3   25 1852   28    5   92  394\n",
      "  216    2  794   24   27  368  633 6349   92  109   11    1   76 1183\n",
      "  683   43  748    2   88 1784    2    1  459   32  411   12   13  350\n",
      "    2  183   54    4   86  663   27  225 3197  648  117   62  670   13\n",
      "    1  664  262    4   50   13    5  292    3 8239   32   13   81   72\n",
      "   27  503    2   44    4   88   70  670 3311  228   92 4758   48    1\n",
      "  107 1111    3  180 1037  664  683 3844   98   64 1936   10  126 8240\n",
      "  133  514 2866    4 2525 1110    6  999   16    5  493   50   13    5\n",
      "  237  520    7  256   63 5594   54 2526    4 9162    2  138    1 1335\n",
      " 2037  670    6 8241   13 2310    2 5278    1 9163    6    1 2172 4542\n",
      "  127    6  676   17  242    1  138    7 1000    4    1 4543   42 1132\n",
      "   54   10    5  221    6    1 2572   17    1  162 6870  243    6  676\n",
      "   16 1000 1998    5   45   76 1183  216   50   13    5 6350    7 9164\n",
      "  923   17   74 1350    5    3   98  102  495    6    1  309 1678 1000\n",
      "  151    1  407   16    5  262  573    3 1388  648   16  256  155   10\n",
      " 3040    4  342   49  484  429    6  237  603    1  108    7 1000   22\n",
      " 2125    5  387 2867    6    1  263 1678   17   15  521  664  683 7493\n",
      "   71  155  221    2  175    1 5952  216  151    1 2573 1678   16    5\n",
      " 3198    3   16  812  676    6  151    1 1461 4157 6871  614   16    5\n",
      " 4984    3   16  812 3039    3   30  417   77    6  237    4  151    1\n",
      " 1335 2525   16  812 8242  237   50   13  412  230  596  493    6    1\n",
      " 1335 3430   17 1539  109  440    3  812 5279 2788 1751 8243   35    2\n",
      " 2405    7  676   51    6    1 2527 3550    3    1 1461 2172  670   17\n",
      " 9162  373  145 5280    3  342 1937  151    1 1461 3430   16  676    7\n",
      "  256  242  493    7 3120    6    1 1335 2037 3312  379    3 2526 9165\n",
      "    4  812 4544 5595   43  114    5   45  417   77  813 4759   39   64\n",
      "  493    6    1 1461 2866   17 3041   60    1   62 1999 4337    2  548\n",
      "  145  812  924    4 1937    5    6    1 2572  400  812  655    1  420\n",
      "    2 1509  383  648   17  342  717  493    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model\n",
    "\n",
    "Based on the size of training data and after numerical experiement, we finally come up with the following structure. In case when we have more and more data in the future, we need to adjust the retrain the model in order to accept more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    inputs = Input(name='inputs',shape=(MAX_LENGTH,))\n",
    "    x = training_word_embedding_layer(inputs)\n",
    "    # x = LSTM(128, return_sequences=True)(x)\n",
    "    x = LSTM(128)(x)\n",
    "    x = Dense(256,name='FC1')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "#     x = LSTM(128)(x)\n",
    "#     x = Dense(256,name='FC2')(x)\n",
    "#     x = Activation('relu')(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = Dropout(0.5)(x) \n",
    "\n",
    "    x = Dense(NUM_CLASSES, name='out_layer')(x)\n",
    "    x = Activation('softmax')(x)\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    return model\n",
    "\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model \n",
    "plot_model(model, to_file='model1.png')\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy', \n",
    "    optimizer=RMSprop(), \n",
    "    metrics=['acc']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the Shape of data Before Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1891, 500)\n",
      "1891\n",
      "(334, 500)\n",
      "334\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(len(Y_train))\n",
    "print(X_test.shape)\n",
    "print(len(Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model using GPU of my GTX-3090 graphic card with cuCNN 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "30/30 [==============================] - 5s 75ms/step - loss: 1.7759 - acc: 0.2691 - val_loss: 1.5722 - val_acc: 0.2575\n",
      "Epoch 2/50\n",
      "30/30 [==============================] - 1s 42ms/step - loss: 1.5164 - acc: 0.3111 - val_loss: 1.5664 - val_acc: 0.2784\n",
      "Epoch 3/50\n",
      "30/30 [==============================] - 1s 42ms/step - loss: 1.4620 - acc: 0.3552 - val_loss: 1.5568 - val_acc: 0.2754\n",
      "Epoch 4/50\n",
      "30/30 [==============================] - 1s 41ms/step - loss: 1.4762 - acc: 0.3445 - val_loss: 1.5323 - val_acc: 0.3144\n",
      "Epoch 5/50\n",
      "30/30 [==============================] - 1s 41ms/step - loss: 1.5323 - acc: 0.3390 - val_loss: 1.5280 - val_acc: 0.2904\n",
      "Epoch 6/50\n",
      "30/30 [==============================] - 1s 41ms/step - loss: 1.4272 - acc: 0.3712 - val_loss: 1.5968 - val_acc: 0.2455\n",
      "Epoch 7/50\n",
      "30/30 [==============================] - 1s 42ms/step - loss: 1.3208 - acc: 0.4110 - val_loss: 1.4095 - val_acc: 0.3832\n",
      "Epoch 8/50\n",
      "30/30 [==============================] - 1s 41ms/step - loss: 1.3168 - acc: 0.4051 - val_loss: 1.4896 - val_acc: 0.3114\n",
      "Epoch 9/50\n",
      "30/30 [==============================] - 1s 43ms/step - loss: 1.3326 - acc: 0.4320 - val_loss: 1.2685 - val_acc: 0.3623\n",
      "Epoch 10/50\n",
      "30/30 [==============================] - 1s 42ms/step - loss: 1.2023 - acc: 0.4772 - val_loss: 1.0864 - val_acc: 0.5210\n",
      "Epoch 11/50\n",
      "30/30 [==============================] - 1s 42ms/step - loss: 1.0930 - acc: 0.5661 - val_loss: 1.3142 - val_acc: 0.4611\n",
      "Epoch 12/50\n",
      "30/30 [==============================] - 1s 42ms/step - loss: 1.1502 - acc: 0.5089 - val_loss: 1.9220 - val_acc: 0.3383\n",
      "Epoch 13/50\n",
      "30/30 [==============================] - 1s 41ms/step - loss: 1.2176 - acc: 0.4475 - val_loss: 1.7408 - val_acc: 0.3084\n",
      "Epoch 14/50\n",
      "30/30 [==============================] - 1s 41ms/step - loss: 1.2763 - acc: 0.4350 - val_loss: 1.6443 - val_acc: 0.2784\n",
      "Epoch 15/50\n",
      "30/30 [==============================] - 1s 42ms/step - loss: 1.2700 - acc: 0.4224 - val_loss: 2.8737 - val_acc: 0.2246\n",
      "Epoch 16/50\n",
      "30/30 [==============================] - 1s 41ms/step - loss: 1.1999 - acc: 0.5146 - val_loss: 1.8483 - val_acc: 0.3772\n",
      "Epoch 17/50\n",
      "30/30 [==============================] - 1s 42ms/step - loss: 1.2976 - acc: 0.4145 - val_loss: 2.8640 - val_acc: 0.2395\n",
      "Epoch 18/50\n",
      "30/30 [==============================] - 1s 43ms/step - loss: 1.2962 - acc: 0.3935 - val_loss: 1.6385 - val_acc: 0.3084\n",
      "Epoch 19/50\n",
      "30/30 [==============================] - 1s 41ms/step - loss: 1.3178 - acc: 0.4010 - val_loss: 8.9286 - val_acc: 0.2006\n",
      "Epoch 20/50\n",
      "30/30 [==============================] - 1s 41ms/step - loss: 1.3480 - acc: 0.3847 - val_loss: 5.5943 - val_acc: 0.2305\n",
      "Epoch 21/50\n",
      "30/30 [==============================] - 1s 42ms/step - loss: 1.2932 - acc: 0.4170 - val_loss: 5.2658 - val_acc: 0.2784\n",
      "Epoch 22/50\n",
      "30/30 [==============================] - 1s 41ms/step - loss: 1.3984 - acc: 0.3718 - val_loss: 3.6177 - val_acc: 0.3802\n",
      "Epoch 23/50\n",
      "30/30 [==============================] - 1s 41ms/step - loss: 1.1735 - acc: 0.4907 - val_loss: 2.7589 - val_acc: 0.4731\n",
      "Epoch 24/50\n",
      "30/30 [==============================] - 1s 42ms/step - loss: 1.0450 - acc: 0.5909 - val_loss: 0.8610 - val_acc: 0.6826\n",
      "Epoch 25/50\n",
      "30/30 [==============================] - 1s 41ms/step - loss: 0.7838 - acc: 0.7036 - val_loss: 0.8719 - val_acc: 0.7246\n",
      "Epoch 26/50\n",
      "30/30 [==============================] - 1s 42ms/step - loss: 0.7216 - acc: 0.7372 - val_loss: 0.8770 - val_acc: 0.6886\n",
      "Epoch 27/50\n",
      "30/30 [==============================] - 1s 41ms/step - loss: 0.9054 - acc: 0.6544 - val_loss: 1.8098 - val_acc: 0.5120\n",
      "Epoch 28/50\n",
      "30/30 [==============================] - 1s 42ms/step - loss: 0.9297 - acc: 0.5798 - val_loss: 0.6535 - val_acc: 0.7665\n",
      "Epoch 29/50\n",
      "30/30 [==============================] - 1s 41ms/step - loss: 0.7885 - acc: 0.7136 - val_loss: 1.1118 - val_acc: 0.6377\n",
      "Epoch 30/50\n",
      "30/30 [==============================] - 1s 41ms/step - loss: 1.0219 - acc: 0.5842 - val_loss: 3.9583 - val_acc: 0.2515\n",
      "Epoch 31/50\n",
      "30/30 [==============================] - 1s 41ms/step - loss: 1.3316 - acc: 0.3985 - val_loss: 2.3864 - val_acc: 0.2814\n",
      "Epoch 32/50\n",
      "30/30 [==============================] - 1s 42ms/step - loss: 0.9905 - acc: 0.5598 - val_loss: 1.0575 - val_acc: 0.7575\n",
      "Epoch 33/50\n",
      "30/30 [==============================] - 1s 41ms/step - loss: 0.6718 - acc: 0.7701 - val_loss: 0.5671 - val_acc: 0.8293\n",
      "Epoch 34/50\n",
      "30/30 [==============================] - 1s 41ms/step - loss: 0.4839 - acc: 0.8421 - val_loss: 0.5210 - val_acc: 0.8713\n",
      "Epoch 35/50\n",
      "30/30 [==============================] - 1s 42ms/step - loss: 0.3895 - acc: 0.8927 - val_loss: 0.3406 - val_acc: 0.9311\n",
      "Epoch 36/50\n",
      "30/30 [==============================] - 1s 41ms/step - loss: 0.4166 - acc: 0.8778 - val_loss: 1.2458 - val_acc: 0.5629\n",
      "Epoch 37/50\n",
      "30/30 [==============================] - 1s 42ms/step - loss: 0.5491 - acc: 0.7809 - val_loss: 0.2897 - val_acc: 0.9222\n",
      "Epoch 38/50\n",
      "30/30 [==============================] - 1s 42ms/step - loss: 0.3810 - acc: 0.8771 - val_loss: 1.2285 - val_acc: 0.7006\n",
      "Epoch 39/50\n",
      "30/30 [==============================] - 1s 42ms/step - loss: 0.5769 - acc: 0.7864 - val_loss: 0.5445 - val_acc: 0.8114\n",
      "Epoch 40/50\n",
      "30/30 [==============================] - 1s 42ms/step - loss: 0.4630 - acc: 0.8388 - val_loss: 0.5364 - val_acc: 0.7814\n",
      "Epoch 41/50\n",
      "30/30 [==============================] - 1s 41ms/step - loss: 0.5212 - acc: 0.8180 - val_loss: 0.5697 - val_acc: 0.7635\n",
      "Epoch 42/50\n",
      "30/30 [==============================] - 1s 42ms/step - loss: 0.4785 - acc: 0.8443 - val_loss: 0.4471 - val_acc: 0.8922\n",
      "Epoch 43/50\n",
      "30/30 [==============================] - 1s 41ms/step - loss: 0.3344 - acc: 0.9088 - val_loss: 0.3357 - val_acc: 0.9281\n",
      "Epoch 44/50\n",
      "30/30 [==============================] - 1s 42ms/step - loss: 0.3262 - acc: 0.9017 - val_loss: 0.3711 - val_acc: 0.8952\n",
      "Epoch 45/50\n",
      "30/30 [==============================] - 1s 42ms/step - loss: 0.3733 - acc: 0.8915 - val_loss: 0.3818 - val_acc: 0.9072\n",
      "Epoch 46/50\n",
      "30/30 [==============================] - 1s 42ms/step - loss: 0.3548 - acc: 0.9184 - val_loss: 0.2362 - val_acc: 0.9341\n",
      "Epoch 47/50\n",
      "30/30 [==============================] - 1s 41ms/step - loss: 0.2904 - acc: 0.9347 - val_loss: 0.2858 - val_acc: 0.9431\n",
      "Epoch 48/50\n",
      "30/30 [==============================] - 1s 41ms/step - loss: 0.2766 - acc: 0.9257 - val_loss: 0.3578 - val_acc: 0.9132\n",
      "Epoch 49/50\n",
      "30/30 [==============================] - 1s 42ms/step - loss: 0.2549 - acc: 0.9287 - val_loss: 0.4084 - val_acc: 0.8982\n",
      "Epoch 50/50\n",
      "30/30 [==============================] - 1s 42ms/step - loss: 0.3633 - acc: 0.8993 - val_loss: 0.4695 - val_acc: 0.8503\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e081995760>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, \n",
    "          Y_train,\n",
    "          validation_data = (X_test, Y_test),\n",
    "          batch_size=64,\n",
    "          epochs=50\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./output/classifier.hdf5\")\n",
    "plot_model(model, to_file='model2.png')\n",
    "\n",
    "# saving\n",
    "with open('./output/tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('./output/labelBinarizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(labelBinarizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the Model from Local Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"./output/classifier.hdf5\")\n",
    "\n",
    "tokenizer = None\n",
    "labelBinarizer = None\n",
    "\n",
    "with open('./output/tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "    \n",
    "with open('./output/labelBinarizer.pickle', 'rb') as handle:\n",
    "    labelBinarizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Prediction Method with Human Readable Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_paragraph_category(paragraph):\n",
    "    seq = np.array(\n",
    "        sequence.pad_sequences(\n",
    "            tokenizer.texts_to_sequences([paragraph.strip()]), \n",
    "            maxlen=MAX_LENGTH, \n",
    "            padding='post')\n",
    "    )\n",
    "    probabilities = model.predict(seq)[0]\n",
    "    index = np.argmax(probabilities)\n",
    "    return labelBinarizer.classes_[index], probabilities[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('entertainment', 0.9367099)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_paragraph_category(contents[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1616\n",
      "[paragraph] double injury blow strikes wales wales centre sonny parker and number eight ryan jones will miss sat...\n",
      "[prediction] business\n",
      "[answer] sport\n",
      "[confidence] 0.49221826\n",
      "------------\n",
      "1091\n",
      "[paragraph] mandelson warning to bbc the bbc should steer away from demonising exdowning street media chief alas...\n",
      "[prediction] politics\n",
      "[answer] politics\n",
      "[confidence] 0.9740305\n",
      "------------\n",
      "1963\n",
      "[paragraph] players sought for 1m prize uk gamers are getting a chance to take part in a 1m tournament thanks to...\n",
      "[prediction] tech\n",
      "[answer] tech\n",
      "[confidence] 0.771528\n",
      "------------\n",
      "1826\n",
      "[paragraph] microsoft seeking spyware trojan microsoft is investigating a trojan program that attempts to switch...\n",
      "[prediction] tech\n",
      "[answer] tech\n",
      "[confidence] 0.98780453\n",
      "------------\n",
      "587\n",
      "[paragraph] baby becomes new oscar favourite clint eastwoods boxing drama million dollar baby has become the new...\n",
      "[prediction] entertainment\n",
      "[answer] entertainment\n",
      "[confidence] 0.94615114\n",
      "------------\n",
      "299\n",
      "[paragraph] jj agrees 25bn guidant deal pharmaceutical giant johnson  johnson has agreed to buy medical technolo...\n",
      "[prediction] business\n",
      "[answer] business\n",
      "[confidence] 0.99880016\n",
      "------------\n",
      "1263\n",
      "[paragraph] act on detention ruling uk urged the government must act quickly on the law lords ruling that detent...\n",
      "[prediction] politics\n",
      "[answer] politics\n",
      "[confidence] 0.9910288\n",
      "------------\n",
      "1163\n",
      "[paragraph] more reforms ahead says milburn labour will continue to pursue controversial reforms if it wins a th...\n",
      "[prediction] politics\n",
      "[answer] politics\n",
      "[confidence] 0.99894947\n",
      "------------\n",
      "1078\n",
      "[paragraph] former ni minister scott dies former northern ireland minister sir nicholas scott has died at a lond...\n",
      "[prediction] politics\n",
      "[answer] politics\n",
      "[confidence] 0.96598303\n",
      "------------\n",
      "1295\n",
      "[paragraph] expm lord callaghan dies aged 92 former labour prime minister lord callaghan has died on the eve of ...\n",
      "[prediction] politics\n",
      "[answer] politics\n",
      "[confidence] 0.9999783\n",
      "------------\n",
      "1795\n",
      "[paragraph] hewitt survives nalbandian epic home favourite lleyton hewitt came through a dramatic fiveset battle...\n",
      "[prediction] sport\n",
      "[answer] sport\n",
      "[confidence] 0.95015275\n",
      "------------\n",
      "883\n",
      "[paragraph] lee to create new film superhero comic book veteran stan lee is to team up with producer robert evan...\n",
      "[prediction] entertainment\n",
      "[answer] entertainment\n",
      "[confidence] 0.9454958\n",
      "------------\n",
      "452\n",
      "[paragraph] us industrial output growth eases us industrial production continued to rise in november albeit at a...\n",
      "[prediction] business\n",
      "[answer] business\n",
      "[confidence] 0.9989526\n",
      "------------\n",
      "1393\n",
      "[paragraph] iaaf will contest greek decision the international association of athletics federations will appeal ...\n",
      "[prediction] business\n",
      "[answer] sport\n",
      "[confidence] 0.4283995\n",
      "------------\n",
      "613\n",
      "[paragraph] glasgow hosts tsunami benefit gig the top names in scottish music are taking part in a benefit conce...\n",
      "[prediction] entertainment\n",
      "[answer] entertainment\n",
      "[confidence] 0.94438154\n",
      "------------\n",
      "1901\n",
      "[paragraph] blog reading explodes in america americans are becoming avid blog readers with 32 million getting ho...\n",
      "[prediction] tech\n",
      "[answer] tech\n",
      "[confidence] 0.98791134\n",
      "------------\n",
      "1142\n",
      "[paragraph] kennedy to make temple address charles kennedy is set to address 2000 people at a hindu temple as pa...\n",
      "[prediction] politics\n",
      "[answer] politics\n",
      "[confidence] 0.9706835\n",
      "------------\n",
      "541\n",
      "[paragraph] redfords vision of sundance despite sporting a corduroy cap pulled low over his face plus a pair of ...\n",
      "[prediction] entertainment\n",
      "[answer] entertainment\n",
      "[confidence] 0.95003664\n",
      "------------\n",
      "683\n",
      "[paragraph] x factor show gets second series tv talent show the x factor is to return for a second series after ...\n",
      "[prediction] entertainment\n",
      "[answer] entertainment\n",
      "[confidence] 0.9424912\n",
      "------------\n",
      "1790\n",
      "[paragraph] clijsters hope on aussie open kim clijsters has denied reports that she has pulled out of januarys a...\n",
      "[prediction] sport\n",
      "[answer] sport\n",
      "[confidence] 0.95015264\n",
      "------------\n",
      "1897\n",
      "[paragraph] china to overtake us net use the chinese netusing population looks set to exceed that of the us in l...\n",
      "[prediction] tech\n",
      "[answer] tech\n",
      "[confidence] 0.87599766\n",
      "------------\n",
      "1517\n",
      "[paragraph] yeading face newcastle in fa cup premiership side newcastle united face a trip to ryman premier leag...\n",
      "[prediction] sport\n",
      "[answer] sport\n",
      "[confidence] 0.9501529\n",
      "------------\n",
      "875\n",
      "[paragraph] bollywood dvd fraudster is jailed a major distributor of pirated dvds of bollywood films has been se...\n",
      "[prediction] entertainment\n",
      "[answer] entertainment\n",
      "[confidence] 0.9442778\n",
      "------------\n",
      "673\n",
      "[paragraph] parkers saxophone heads auction a saxophone belonging to legendary jazz musician charlie parker is e...\n",
      "[prediction] business\n",
      "[answer] entertainment\n",
      "[confidence] 0.5890014\n",
      "------------\n",
      "1239\n",
      "[paragraph] will tory tax cuts lift spirits michael howard has finally revealed the full scale of his planned to...\n",
      "[prediction] politics\n",
      "[answer] politics\n",
      "[confidence] 0.9961785\n",
      "------------\n",
      "1791\n",
      "[paragraph] clijsters could play aussie open kim clijsters has denied reports that she has pulled out of january...\n",
      "[prediction] sport\n",
      "[answer] sport\n",
      "[confidence] 0.95015234\n",
      "------------\n",
      "819\n",
      "[paragraph] bbc denies blackadder tv comeback the bbc has said there are no plans in the pipeline for a new seri...\n",
      "[prediction] business\n",
      "[answer] entertainment\n",
      "[confidence] 0.5784666\n",
      "------------\n",
      "1473\n",
      "[paragraph] coach ranieri sacked by valencia claudio ranieri has been sacked as valencia coach just eight months...\n",
      "[prediction] sport\n",
      "[answer] sport\n",
      "[confidence] 0.95015234\n",
      "------------\n",
      "1727\n",
      "[paragraph] wilkinson to miss ireland match england will have to take on ireland in the six nations without capt...\n",
      "[prediction] business\n",
      "[answer] sport\n",
      "[confidence] 0.4599816\n",
      "------------\n",
      "1490\n",
      "[paragraph] cole refuses to blame van persie ashley cole has refused to blame robin van persie for leaving arsen...\n",
      "[prediction] business\n",
      "[answer] sport\n",
      "[confidence] 0.5107465\n",
      "------------\n",
      "1278\n",
      "[paragraph] labour accused of eu propaganda a taxpayer subsidised propaganda exercise on the eu is being used to...\n",
      "[prediction] politics\n",
      "[answer] politics\n",
      "[confidence] 0.99963105\n",
      "------------\n",
      "999\n",
      "[paragraph] royal couple watch nations mood prince charles and camilla parker bowles are awaiting the nations re...\n",
      "[prediction] politics\n",
      "[answer] politics\n",
      "[confidence] 0.97429466\n",
      "------------\n",
      "252\n",
      "[paragraph] jobs growth still slow in the us the us created fewer jobs than expected in january but a fall in jo...\n",
      "[prediction] business\n",
      "[answer] business\n",
      "[confidence] 0.9988826\n",
      "------------\n",
      "120\n",
      "[paragraph] us interest rates increased to 2 us interest rates are to rise for the fourth time in five months in...\n",
      "[prediction] business\n",
      "[answer] business\n",
      "[confidence] 0.9998423\n",
      "------------\n",
      "864\n",
      "[paragraph] bafta to hand out movie honours movie stars from across the globe are attending this years bafta fil...\n",
      "[prediction] entertainment\n",
      "[answer] entertainment\n",
      "[confidence] 0.9994324\n",
      "------------\n",
      "1056\n",
      "[paragraph] turkey deal to help world peace a deal bringing turkey a step closer to eu membership is of fundamen...\n",
      "[prediction] politics\n",
      "[answer] politics\n",
      "[confidence] 0.96882105\n",
      "------------\n",
      "1005\n",
      "[paragraph] uk heading wrong way  howard tony blair has had the chance to tackle the problems facing britain and...\n",
      "[prediction] politics\n",
      "[answer] politics\n",
      "[confidence] 0.9834415\n",
      "------------\n",
      "1202\n",
      "[paragraph] conservative mp defects to labour a conservative mp and former minister has defected to labour rober...\n",
      "[prediction] politics\n",
      "[answer] politics\n",
      "[confidence] 0.96731913\n",
      "------------\n",
      "1369\n",
      "[paragraph] what now for kelly holmes last april kelly holmes spoke to the bbc sport website about her lonelines...\n",
      "[prediction] sport\n",
      "[answer] sport\n",
      "[confidence] 0.5656502\n",
      "------------\n",
      "705\n",
      "[paragraph] gervais writing simpsons episode the offices ricky gervais is writing an episode of hit us cartoon t...\n",
      "[prediction] entertainment\n",
      "[answer] entertainment\n",
      "[confidence] 0.94586533\n",
      "------------\n",
      "1151\n",
      "[paragraph] blair pledges unity to labour mps tony blair has sought to reassure labour backbenchers that nothing...\n",
      "[prediction] politics\n",
      "[answer] politics\n",
      "[confidence] 0.99788886\n",
      "------------\n",
      "721\n",
      "[paragraph] little britain two top comic list little britain stars matt lucas and david walliams have been named...\n",
      "[prediction] entertainment\n",
      "[answer] entertainment\n",
      "[confidence] 0.9422202\n",
      "------------\n",
      "311\n",
      "[paragraph] parmalat sues 45 banks over crash parmalat has sued 45 banks as it tries to reclaim money paid to ba...\n",
      "[prediction] business\n",
      "[answer] business\n",
      "[confidence] 0.99894613\n",
      "------------\n",
      "1366\n",
      "[paragraph] thanou bullish over drugs hearing katerina thanou is confident she and fellow sprinter kostas kenter...\n",
      "[prediction] politics\n",
      "[answer] sport\n",
      "[confidence] 0.96128994\n",
      "------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1455\n",
      "[paragraph] wenger handed summer war chest arsenal boss arsene wenger has been guaranteed transfer funds to boos...\n",
      "[prediction] sport\n",
      "[answer] sport\n",
      "[confidence] 0.95015264\n",
      "------------\n",
      "725\n",
      "[paragraph] housewives lift channel 4 ratings the debut of us television hit desperate housewives has helped lif...\n",
      "[prediction] entertainment\n",
      "[answer] entertainment\n",
      "[confidence] 0.94845647\n",
      "------------\n",
      "950\n",
      "[paragraph] kelly trails new discipline power teachers could get more powers to remove unruly pupils from classe...\n",
      "[prediction] politics\n",
      "[answer] politics\n",
      "[confidence] 0.9850677\n",
      "------------\n",
      "1172\n",
      "[paragraph] howard and blair tax pledge clash tony blair has said voters will have to wait for labours manifesto...\n",
      "[prediction] politics\n",
      "[answer] politics\n",
      "[confidence] 0.9699224\n",
      "------------\n",
      "136\n",
      "[paragraph] bank set to leave rates on hold uk interest rates are set to remain on hold at 475 following the lat...\n",
      "[prediction] business\n",
      "[answer] business\n",
      "[confidence] 0.99884725\n",
      "------------\n",
      "1241\n",
      "[paragraph] labours four little words labour has unveiled the four little words that will form the heart of its ...\n",
      "[prediction] politics\n",
      "[answer] politics\n",
      "[confidence] 0.97316486\n",
      "------------\n",
      "101\n",
      "[paragraph] us company admits benin bribery a us defence and telecommunications company has agreed to pay 285m a...\n",
      "[prediction] business\n",
      "[answer] business\n",
      "[confidence] 0.99876547\n",
      "------------\n",
      "1177\n",
      "[paragraph] blair blasts tory spending plans tony blair has launched an attack on conservative spending plans sa...\n",
      "[prediction] politics\n",
      "[answer] politics\n",
      "[confidence] 0.9997532\n",
      "------------\n",
      "218\n",
      "[paragraph] rescue hope for borussia dortmund shares in struggling german football club borussia dortmund slippe...\n",
      "[prediction] business\n",
      "[answer] business\n",
      "[confidence] 0.9988164\n",
      "------------\n",
      "644\n",
      "[paragraph] vibe awards back despite violence the us vibe awards will be held again next year despite a stabbing...\n",
      "[prediction] business\n",
      "[answer] entertainment\n",
      "[confidence] 0.58512247\n",
      "------------\n",
      "1728\n",
      "[paragraph] italy 838 wales wales secured their first away win in the rbs six nations for nearly four years with...\n",
      "[prediction] sport\n",
      "[answer] sport\n",
      "[confidence] 0.99146867\n",
      "------------\n",
      "708\n",
      "[paragraph] 16318m indecency fine for viacom media giant viacom has paid out 35m â£18m to end investigations int...\n",
      "[prediction] entertainment\n",
      "[answer] entertainment\n",
      "[confidence] 0.94406056\n",
      "------------\n",
      "1031\n",
      "[paragraph] straw attacked on china arms moves to lift the european unions ban on arms exports to china have bee...\n",
      "[prediction] politics\n",
      "[answer] politics\n",
      "[confidence] 0.9860367\n",
      "------------\n",
      "349\n",
      "[paragraph] dollar hits new low versus euro the us dollar has continued its recordbreaking slide and has tumbled...\n",
      "[prediction] business\n",
      "[answer] business\n",
      "[confidence] 0.99884355\n",
      "------------\n",
      "1411\n",
      "[paragraph] smith keen on home series return scotland manager walter smith has given his backing to the reinstat...\n",
      "[prediction] business\n",
      "[answer] sport\n",
      "[confidence] 0.3434614\n",
      "------------\n",
      "140\n",
      "[paragraph] bmw reveals new models pipeline bmw is preparing to enter the market for carstyle people carriers th...\n",
      "[prediction] business\n",
      "[answer] business\n",
      "[confidence] 0.99884653\n",
      "------------\n",
      "1294\n",
      "[paragraph] tories reject rethink on axed mp sacked mp howard flights local conservative association has insiste...\n",
      "[prediction] politics\n",
      "[answer] politics\n",
      "[confidence] 0.9999287\n",
      "------------\n",
      "739\n",
      "[paragraph] aaliyah claim dismissed by court late rb star aaliyahs record company has failed in an attempt to su...\n",
      "[prediction] business\n",
      "[answer] entertainment\n",
      "[confidence] 0.57104945\n",
      "------------\n",
      "554\n",
      "[paragraph] jugnot tops french actor league actor gerard jugnot  star of the oscarnominated film the chorus  has...\n",
      "[prediction] entertainment\n",
      "[answer] entertainment\n",
      "[confidence] 0.9457466\n",
      "------------\n",
      "287\n",
      "[paragraph] ge sees excellent world economy us behemoth general electric has posted an 18 jump in quarterly sale...\n",
      "[prediction] business\n",
      "[answer] business\n",
      "[confidence] 0.99889565\n",
      "------------\n",
      "1587\n",
      "[paragraph] beckham rules out management move real madrid midfielder david beckham has no plans to become a mana...\n",
      "[prediction] business\n",
      "[answer] sport\n",
      "[confidence] 0.51251155\n",
      "------------\n",
      "445\n",
      "[paragraph] us in eu tariff chaos trade row the us has asked the world trade organisation to investigate europea...\n",
      "[prediction] business\n",
      "[answer] business\n",
      "[confidence] 0.99871707\n",
      "------------\n",
      "1875\n",
      "[paragraph] xbox 2 may be unveiled in summer details of the next generation of microsofts xbox games console  co...\n",
      "[prediction] tech\n",
      "[answer] tech\n",
      "[confidence] 0.9886154\n",
      "------------\n",
      "571\n",
      "[paragraph] spirit awards hail sideways the comedy sideways has dominated this years independent spirit awards w...\n",
      "[prediction] entertainment\n",
      "[answer] entertainment\n",
      "[confidence] 0.9446989\n",
      "------------\n",
      "193\n",
      "[paragraph] postchristmas lull in lending uk mortgage lending showed a postchristmas lull in january indicating ...\n",
      "[prediction] business\n",
      "[answer] business\n",
      "[confidence] 0.9988481\n",
      "------------\n",
      "33\n",
      "[paragraph] rover deal may cost 2000 jobs some 2000 jobs at mg rovers midlands plant may be cut if investment in...\n",
      "[prediction] business\n",
      "[answer] business\n",
      "[confidence] 0.9989002\n",
      "------------\n",
      "1687\n",
      "[paragraph] dallaglio his own man to the end controversy and lawrence dallaglio have never been very far away fr...\n",
      "[prediction] sport\n",
      "[answer] sport\n",
      "[confidence] 0.8962326\n",
      "------------\n",
      "1576\n",
      "[paragraph] oleary agrees new villa contract aston villa boss david oleary signed a threeandahalf year contract ...\n",
      "[prediction] business\n",
      "[answer] sport\n",
      "[confidence] 0.50345695\n",
      "------------\n",
      "301\n",
      "[paragraph] cactus diet deal for phytopharm a slimming aid made from a southern african cactus is set to be deve...\n",
      "[prediction] business\n",
      "[answer] business\n",
      "[confidence] 0.9988349\n",
      "------------\n",
      "768\n",
      "[paragraph] rapper kanye wests shrewd soul us hiphop star kanye west  who leads the race for this years grammys ...\n",
      "[prediction] entertainment\n",
      "[answer] entertainment\n",
      "[confidence] 0.9085542\n",
      "------------\n",
      "1298\n",
      "[paragraph] voters dont trust politicians eight out of 10 voters do not trust politicians to tell the truth a ne...\n",
      "[prediction] politics\n",
      "[answer] politics\n",
      "[confidence] 0.9840236\n",
      "------------\n",
      "566\n",
      "[paragraph] dutch watch van goghs last film the last film to be made by the slain dutch director theo van gogh c...\n",
      "[prediction] business\n",
      "[answer] entertainment\n",
      "[confidence] 0.5622249\n",
      "------------\n",
      "1761\n",
      "[paragraph] what now for british tennis tim henmans decision to quit davis cup tennis has left the british team ...\n",
      "[prediction] business\n",
      "[answer] sport\n",
      "[confidence] 0.43808022\n",
      "------------\n",
      "874\n",
      "[paragraph] tarantino to direct csi episode film director quentin tarantino is to direct an episode of us televi...\n",
      "[prediction] entertainment\n",
      "[answer] entertainment\n",
      "[confidence] 0.9460362\n",
      "------------\n",
      "888\n",
      "[paragraph] tarantino to make friday sequel director quentin tarantino is in talks to write and direct a new ins...\n",
      "[prediction] entertainment\n",
      "[answer] entertainment\n",
      "[confidence] 0.94711757\n",
      "------------\n",
      "1140\n",
      "[paragraph] army chiefs in regiments decision military chiefs are expected to meet to make a final decision on t...\n",
      "[prediction] politics\n",
      "[answer] politics\n",
      "[confidence] 0.98330253\n",
      "------------\n",
      "348\n",
      "[paragraph] s korean lender faces liquidation creditors of south koreas top credit card firm have said they will...\n",
      "[prediction] business\n",
      "[answer] business\n",
      "[confidence] 0.9989976\n",
      "------------\n",
      "1203\n",
      "[paragraph] tory stalking horse meyer dies sir anthony meyer the tory backbencher who challenged margaret thatch...\n",
      "[prediction] politics\n",
      "[answer] politics\n",
      "[confidence] 0.9504285\n",
      "------------\n",
      "1881\n",
      "[paragraph] bt boosts its broadband packages british telecom has said it will double the broadband speeds of mos...\n",
      "[prediction] tech\n",
      "[answer] tech\n",
      "[confidence] 0.7745262\n",
      "------------\n",
      "323\n",
      "[paragraph] yukos seeks court action on sale yukos will return to a us court on wednesday to seek sanctions agai...\n",
      "[prediction] business\n",
      "[answer] business\n",
      "[confidence] 0.9990277\n",
      "------------\n",
      "726\n",
      "[paragraph] baywatch dubbed worst tv import surf show baywatch has won the title of worst tv import of all time ...\n",
      "[prediction] entertainment\n",
      "[answer] entertainment\n",
      "[confidence] 0.94361657\n",
      "------------\n",
      "132\n",
      "[paragraph] salary scandal in cameroon cameroon says widespread corruption in its finance ministry has cost it 1...\n",
      "[prediction] business\n",
      "[answer] business\n",
      "[confidence] 0.99828255\n",
      "------------\n",
      "1934\n",
      "[paragraph] sony wares win innovation award sony has taken the prize for top innovator at the annual awards of p...\n",
      "[prediction] tech\n",
      "[answer] tech\n",
      "[confidence] 0.9875772\n",
      "------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "706\n",
      "[paragraph] john peel replacement show begins the permanent replacement for late dj john peels bbc radio 1 show ...\n",
      "[prediction] entertainment\n",
      "[answer] entertainment\n",
      "[confidence] 0.90526944\n",
      "------------\n",
      "714\n",
      "[paragraph] wife swap makers sue us copycat the british producers of us wife swap are taking legal action agains...\n",
      "[prediction] business\n",
      "[answer] entertainment\n",
      "[confidence] 0.58350396\n",
      "------------\n",
      "1196\n",
      "[paragraph] taxes must be trusted  kennedy public trust in taxes is breaking down because labour and tories are ...\n",
      "[prediction] politics\n",
      "[answer] politics\n",
      "[confidence] 0.99901795\n",
      "------------\n",
      "1957\n",
      "[paragraph] gates opens biggest gadget fair bill gates has opened the consumer electronics show ces in las vegas...\n",
      "[prediction] tech\n",
      "[answer] tech\n",
      "[confidence] 0.9979461\n",
      "------------\n",
      "401\n",
      "[paragraph] us interest rate rise expected us interest rates are expected to rise for the fifth time since june ...\n",
      "[prediction] business\n",
      "[answer] business\n",
      "[confidence] 0.99894804\n",
      "------------\n",
      "67\n",
      "[paragraph] india seeks to boost construction india has cleared a proposal allowing up to 100 foreign direct inv...\n",
      "[prediction] business\n",
      "[answer] business\n",
      "[confidence] 0.9989556\n",
      "------------\n",
      "1631\n",
      "[paragraph] pountney handed ban and fine northampton coach budge pountney has been fined â£2000 and banned from ...\n",
      "[prediction] sport\n",
      "[answer] sport\n",
      "[confidence] 0.95015234\n",
      "------------\n",
      "1773\n",
      "[paragraph] rusedski angry over supplements greg rusedski has criticised the governing body of mens tennis for n...\n",
      "[prediction] business\n",
      "[answer] sport\n",
      "[confidence] 0.49022314\n",
      "------------\n",
      "994\n",
      "[paragraph] blair stresses prosperity goals tony blair says his partys next manifesto will be unremittingly new ...\n",
      "[prediction] politics\n",
      "[answer] politics\n",
      "[confidence] 0.97465605\n",
      "------------\n",
      "1013\n",
      "[paragraph] bid to cut court witness stress new targets to reduce the stress to victims and witnesses giving evi...\n",
      "[prediction] politics\n",
      "[answer] politics\n",
      "[confidence] 0.9745035\n",
      "------------\n",
      "944\n",
      "[paragraph] clarke to press on with id cards new home secretary charles clarke has vowed to plough on with plans...\n",
      "[prediction] politics\n",
      "[answer] politics\n",
      "[confidence] 0.9835212\n",
      "------------\n",
      "767\n",
      "[paragraph] no jail for singer courtney love singer courtney love has been spared jail for assault and drug offe...\n",
      "[prediction] entertainment\n",
      "[answer] entertainment\n",
      "[confidence] 0.9419703\n",
      "------------\n",
      "338\n",
      "[paragraph] indias deccan seals 18bn deal air deccan has ordered 30 airbus a320 planes in a 18bn â£931m deal as ...\n",
      "[prediction] business\n",
      "[answer] business\n",
      "[confidence] 0.99888724\n",
      "------------\n",
      "accuracy: 99.84%\n"
     ]
    }
   ],
   "source": [
    "wrong_answer = []\n",
    "\n",
    "for index in random.sample(range(0, 2000), 100):\n",
    "    content = contents[index]\n",
    "    label = labels[index]\n",
    "    prediction, score = predict_paragraph_category(content)\n",
    "        \n",
    "    if label != prediction:\n",
    "        wrong_answer.append(index)\n",
    "    \n",
    "    print(index)\n",
    "    print(f\"[paragraph] {content[0:100]}...\")\n",
    "    print(\"[prediction]\", prediction)\n",
    "    print(\"[answer]\", label)\n",
    "    print(\"[confidence]\", score)\n",
    "    print(\"------------\")\n",
    "\n",
    "print(f\"accuracy: {(100 - len(wrong_answer)/100)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction from Latest News (outside of the dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('business', 0.99860305)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph = remove_punctuation(\"The Competition and Markets Authority found local competition concerns regarding fuel in 37 areas in the UK. Zuber and Mohsin Issa, and TDR Capital, agreed to buy Asda for £6.8bn last year. However, they also own 395 UK petrol stations while Asda owns 323.\")                         \n",
    "                               \n",
    "predict_paragraph_category(paragraph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-2.4-cuda11",
   "language": "python",
   "name": "tensorflow-2.4-cuda11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
